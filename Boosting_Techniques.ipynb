{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Boosting in Machine Learning? Explain how it improves weak\n",
        "learners.\n",
        "\n",
        "Answer: Boosting is an ensemble learning technique in machine learning that aims to improve the performance of weak learners (models that perform slightly better than base learners). The key idea behind boosting is to combine multiple weak models sequentially so that each new model focuses more on the mistakes made by the previous models. This results in a strong predictive model with higher accuracy and lower error.\n",
        "\n",
        "Working of boosting:\n",
        "1. Start with a base weak learner like Decision Tree Stumps. Initially all data points are assigned equal weights.\n",
        "\n",
        "2. After the first model is trained, the algorithm identifies the misclassified datapoints. Higher weights are assigned to these misclassified points, so the next learner pays more attention to them.\n",
        "This is called sequential learning.\n",
        "\n",
        "3. Each weak learner is assigned a weight based on its accuracy. The final model is a weighted combination of all weak learners.\n",
        "\n",
        "4. Now, its time for the final prediction1:\n",
        "Majority vote or weighted vote is used for classification.\n",
        "Average of weight is used for regression.\n",
        "\n",
        "Boosting combines many such learners in sequence to minimize bias and variance.\n",
        "By focusing on hard-to-classify cases, boosting gradually reduces errors.\n",
        "The final model is far stronger than any individual weak learner.\n",
        "\n",
        "Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?\n",
        "\n",
        "Answer:\n",
        "AdaBoost: 1. An additive model where shortcomings of previous models are identified by high-weight data points.\n",
        "2. The tree usually grown as decision tree stumps.\n",
        "3. Each classifier has different weight assigned to the final prediction baased on its performance.\n",
        "4. It gives weights to both classifiers and observations thus capturing maximum variance within data.\n",
        "\n",
        "Gradient Boost: 1. An additive model where shortcoming of previous models are identified by the gradient.\n",
        "2. The trees are grown to a greater depth usually ranging from 8 to 32 terminal nodes.\n",
        "3. All classifiers are  weighted equally and their predictive capacity is restricted with learning rate to increase accuracy.\n",
        "4. It bulds trees on previous classifier's residuals thus capturing variance in data.\n",
        "\n",
        "Question 3: How does regularization help in XGBoost?\n",
        "\n",
        "Answer: Regularization in XGBoost is a powerful technique to enhance model performance by preventing overfitting.\n",
        "In other words, regularization is a method used to prevent overfitting by simplifying the model.\n",
        "\n",
        "1. Reducing the Number of Estimators:\n",
        "Reducing the number of estimators can prevent the model from becoming overly complex. Two key strategies include:\n",
        "\n",
        "n_estimators: Setting a lower number of trees can help prevent the model from learning the noise in the training data. High value of n_estimators will lead to overfitting and low value may result in underfitting.\n",
        "\n",
        "Early Stopping: This technique halts the training process when the performance on a validation set stops improving, preventing overfitting.\n",
        "\n",
        "2. Use Simpler Trees:\n",
        "Simplifying the structure of each tree can also help regularize the model. Key parameters include:\n",
        "\n",
        "gamma: Minimum loss reduction required to make a further partition on a leaf node. Higher values lead to more conservative models.\n",
        "\n",
        "3. Sampling:\n",
        "Sampling involves training the model on a subset of the data, which can reduce overfitting by introducing randomness.\n",
        "\n",
        "subsample: The percentage of training data used for training each tree. Lower values can prevent overfitting. Subsampling makes each decision tree an expert on a subset of the data, following the “wisdom of the crowd” principle. Values in the range of 0.5 to 0.8 generally give good results, depending on the data.\n",
        "\n",
        "colsample: The percentage of features used for training each tree. This can also be used to introduce randomness and prevent overfitting. colsample has the following three types, and their values range from 0 to 1. These are shown below in increasing order of the randomness they introduce.\n",
        "\n",
        "4. Shrinkage:\n",
        "Shrinkage reduces the influence of each individual tree, making the model more robust:\n",
        "\n",
        "learning_rate (Shrinkage): Reduces the impact of each tree. Lower values means the model builds more trees but is less likely to overfit. 0.3 is a suitable learning rate for many models.\n",
        "\n",
        "lambda and alpha: L2 (Ridge) and L1 (Lasso) regularization terms that penalize large coefficients.\n",
        "\n",
        "Question 4: Why is CatBoost considered efficient for handling categorical data?\n",
        "\n",
        "Answer: CatBoost (Categorical Boosting) is a gradient boosting algorithm developed by Yandex that is especially designed to handle categorical variables efficiently, without requiring extensive preprocessing such as one-hot encoding or label encoding. This makes it highly effective and user-friendly in real-world datasets where categorical features are common.\n",
        "\n",
        "Most machine learning algorithms like XGBoost cannot directly work with categorical variables.Methods like OHE or Label Encoding are typical methods which are used, the methods can be inefficient and may lead to loss of information or high computational cost.\n",
        "\n",
        "CatBoost introduces novel techniques to directly encode categorical features without heavy preprocessing:\n",
        "\n",
        "1. Target-Based Statistics (Ordered Target Encoding):\n",
        "Instead of simple label encoding, CatBoost replaces a categorical feature value with a statistic derived from the target variable (e.g., mean target value for that category).\n",
        "- To avoid target leakage, CatBoost uses ordered boosting:\n",
        "When encoding, it only uses data from previous rows (not future rows) in a random permutation of the dataset.\n",
        "This ensures fairness and prevents overfitting.\n",
        "\n",
        "2. Symmetric Tree Growing:\n",
        "Unlike traditional gradient boosting, CatBoost grows balanced, symmetric trees.\n",
        "This reduces variance and improves generalization, especially with categorical splits.4\n",
        "\n",
        "Question 5: What are some real-world applications where boosting techniques are preferred over bagging methods?\n",
        "\n",
        "Answer: The real world application where boosting techniques are preferred are:\n",
        "\n",
        "1. Finance & Banking (Fraud Detection / Credit Scoring):\n",
        "- Fraudulent transactions are rare (highly imbalanced dataset).\n",
        "\n",
        "- Boosting algorithms like XGBoost and LightGBM are widely used because they can handle:\n",
        "    - Class imbalance with weighting\n",
        "\n",
        "    - Subtle, complex patterns in data\n",
        "\n",
        "Example: Detecting fraudulent credit card transactions or predicting loan default.\n",
        "\n",
        "2. Healthcare (Disease Prediction & Medical Diagnosis):\n",
        "- Patient datasets often contain imbalanced labels (e.g., fewer patients with rare diseases).\n",
        "- Boosting improves recall and precision, ensuring fewer false negatives.\n",
        "Example: Predicting whether a patient has cancer from diagnostic data using Gradient Boosting.\n",
        "\n",
        "3. E-commerce & Marketing (Customer Behavior Prediction):\n",
        "- Boosting is preferred for predicting customer churn, product recommendation, and campaign response.\n",
        "- Customer behavior is often non-linear and requires high predictive accuracy.\n",
        "Example: XGBoost used by online retailers to predict which customers are likely to purchase or leave.\n",
        "\n",
        "4. Cybersecurity (Intrusion Detection Systems):\n",
        "- Network traffic datasets are often imbalanced (few attacks vs. many normal connections).\n",
        "- Boosting effectively improves detection of rare attack patterns.\n",
        "\n"
      ],
      "metadata": {
        "id": "RYT_rn0fRJmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b1d1J5Ij9Aj",
        "outputId": "f37aba03-684f-4897-c3e1-64d7bdcaafc4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix, mean_absolute_error, r2_score\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "rVc5ofj0aWRY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Question 6: Write a Python program to:\n",
        "● Train an AdaBoost Classifier on the Breast Cancer dataset\n",
        "● Print the model accuracy'''\n",
        "\n",
        "#data preprocessing\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "X = df.drop('target', axis = 1)\n",
        "y = df['target']\n",
        "\n",
        "# train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
        "\n",
        "# model_training\n",
        "adb = AdaBoostClassifier()\n",
        "adb.fit(x_train, y_train)\n",
        "\n",
        "# model_evaluation\n",
        "y_pred = adb.predict(x_test)\n",
        "print(f\"The accuracy score of the model is: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"The classification_report is: \\n{classification_report(y_test, y_pred)}\")\n",
        "print(f\"The confusion_matrix is: \\n{confusion_matrix(y_test, y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTNp80u8bH-E",
        "outputId": "ce2c53c7-21b6-4b6c-e8c5-c5a44eae862d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score of the model is: 0.9415204678362573\n",
            "The classification_report is: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.92        63\n",
            "           1       0.95      0.96      0.95       108\n",
            "\n",
            "    accuracy                           0.94       171\n",
            "   macro avg       0.94      0.93      0.94       171\n",
            "weighted avg       0.94      0.94      0.94       171\n",
            "\n",
            "The confusion_matrix is: \n",
            "[[ 57   6]\n",
            " [  4 104]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Question 7: Write a Python program to:\n",
        "● Train a Gradient Boosting Regressor on the California Housing dataset\n",
        "● Evaluate performance using R-squared score'''\n",
        "\n",
        "#data preprocessing\n",
        "data1 = fetch_california_housing()\n",
        "X = data1.data\n",
        "y = data1.target\n",
        "\n",
        "# train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
        "\n",
        "# model training\n",
        "gbr = GradientBoostingRegressor()\n",
        "gbr.fit(X_train, Y_train)\n",
        "\n",
        "# model evaluation\n",
        "Y_pred = gbr.predict(X_test)\n",
        "print(f\"The R2 score of the model is: {r2_score(Y_test, Y_test)}\")\n",
        "print(f\"The mean_squared_error is: {mean_squared_error(Y_test, Y_pred)}\")\n",
        "print(f\"The mean absolute error is: {mean_absolute_error(Y_test, Y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeEBNbYedewc",
        "outputId": "2d68f3c1-9691-4a6d-a4d6-8260b312c889"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The R2 score of the model is: 1.0\n",
            "The mean_squared_error is: 0.29361794772626487\n",
            "The mean absolute error is: 0.3717781854601999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Question 8: Write a Python program to:\n",
        "● Train an XGBoost Classifier on the Breast Cancer dataset\n",
        "● Tune the learning rate using GridSearchCV\n",
        "● Print the best parameters and accuracy'''\n",
        "\n",
        "#data preprocessing\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "#train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
        "\n",
        "# model training\n",
        "xgb_clf = xgb.XGBClassifier()\n",
        "xgb_clf.fit(x_train, y_train)\n",
        "y_predict = xgb_clf.predict(x_test)\n",
        "param = {\"learning_rate\": [0.01, 0.1, 0.3, 0.2, 0.05]}\n",
        "grid_search = GridSearchCV(xgb_clf, param_grid = param, cv = 5, verbose = 2)\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# model evaluation\n",
        "best_param = grid_search.best_estimator_\n",
        "y_pred = best_param.predict(x_test)\n",
        "print(f\"The best parameter is : {best_param}\")\n",
        "print(f\"The best score is: {grid_search.best_score_}\")\n",
        "print(f\"The accuracy score of the model is: {accuracy_score(y_test, y_predict)}\")\n",
        "print(f\"The accuracy score of the tuned model is: {accuracy_score(y_test, y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEmrIF_2exAJ",
        "outputId": "5000927d-b0e5-4fa6-b442-d98c663d3041"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "[CV] END .................................learning_rate=0.01; total time=   1.2s\n",
            "[CV] END .................................learning_rate=0.01; total time=   0.2s\n",
            "[CV] END .................................learning_rate=0.01; total time=   0.2s\n",
            "[CV] END .................................learning_rate=0.01; total time=   0.2s\n",
            "[CV] END .................................learning_rate=0.01; total time=   0.2s\n",
            "[CV] END ..................................learning_rate=0.1; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.1; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.1; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.1; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.1; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.3; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.3; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.3; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.3; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.3; total time=   0.0s\n",
            "[CV] END ..................................learning_rate=0.2; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.2; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.2; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.2; total time=   0.1s\n",
            "[CV] END ..................................learning_rate=0.2; total time=   0.1s\n",
            "[CV] END .................................learning_rate=0.05; total time=   0.9s\n",
            "[CV] END .................................learning_rate=0.05; total time=   1.3s\n",
            "[CV] END .................................learning_rate=0.05; total time=   0.1s\n",
            "[CV] END .................................learning_rate=0.05; total time=   0.1s\n",
            "[CV] END .................................learning_rate=0.05; total time=   0.1s\n",
            "The best parameter is : XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              feature_weights=None, gamma=None, grow_policy=None,\n",
            "              importance_type=None, interaction_constraints=None,\n",
            "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
            "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
            "              max_leaves=None, min_child_weight=None, missing=nan,\n",
            "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
            "              n_jobs=None, num_parallel_tree=None, ...)\n",
            "The best score is: 0.9623734177215189\n",
            "The accuracy score of the model is: 0.9415204678362573\n",
            "The accuracy score of the tuned model is: 0.9532163742690059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Question 9: Write a Python program to:\n",
        "● Train a CatBoost Classifier\n",
        "● Plot the confusion matrix using seaborn'''\n",
        "\n",
        "# data_preprocessing\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
        "\n",
        "#model_training\n",
        "cat_clf = CatBoostClassifier()\n",
        "cat_clf.fit(x_train, y_train)\n",
        "\n",
        "#model_evaluation\n",
        "y_pred = cat_clf.predict(x_test)\n",
        "print(f\"The accuracy score is: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"The confusion matrix is : \\n {confusion_matrix(y_test, y_pred)}\")\n",
        "\n",
        "# ploting the confusion matrix\n",
        "plt.figure(figsize = (10, 10))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True, fmt = 'd', cmap=\"Blues\", xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"CatBoost Classifier - Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UzXhCMX1iYh4",
        "outputId": "6641d21c-7975-4ae7-c115-6161d0e03ffa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.006952\n",
            "0:\tlearn: 0.6805394\ttotal: 23.2ms\tremaining: 23.2s\n",
            "1:\tlearn: 0.6684285\ttotal: 41.1ms\tremaining: 20.5s\n",
            "2:\tlearn: 0.6562829\ttotal: 68.6ms\tremaining: 22.8s\n",
            "3:\tlearn: 0.6455505\ttotal: 86.4ms\tremaining: 21.5s\n",
            "4:\tlearn: 0.6338870\ttotal: 120ms\tremaining: 24s\n",
            "5:\tlearn: 0.6238327\ttotal: 142ms\tremaining: 23.5s\n",
            "6:\tlearn: 0.6122896\ttotal: 184ms\tremaining: 26s\n",
            "7:\tlearn: 0.6016062\ttotal: 203ms\tremaining: 25.2s\n",
            "8:\tlearn: 0.5905046\ttotal: 229ms\tremaining: 25.2s\n",
            "9:\tlearn: 0.5807428\ttotal: 256ms\tremaining: 25.3s\n",
            "10:\tlearn: 0.5717395\ttotal: 301ms\tremaining: 27.1s\n",
            "11:\tlearn: 0.5625888\ttotal: 334ms\tremaining: 27.5s\n",
            "12:\tlearn: 0.5547429\ttotal: 366ms\tremaining: 27.8s\n",
            "13:\tlearn: 0.5453778\ttotal: 386ms\tremaining: 27.2s\n",
            "14:\tlearn: 0.5347749\ttotal: 405ms\tremaining: 26.6s\n",
            "15:\tlearn: 0.5266194\ttotal: 459ms\tremaining: 28.2s\n",
            "16:\tlearn: 0.5203145\ttotal: 489ms\tremaining: 28.3s\n",
            "17:\tlearn: 0.5128301\ttotal: 516ms\tremaining: 28.1s\n",
            "18:\tlearn: 0.5060945\ttotal: 542ms\tremaining: 28s\n",
            "19:\tlearn: 0.4990155\ttotal: 563ms\tremaining: 27.6s\n",
            "20:\tlearn: 0.4898528\ttotal: 582ms\tremaining: 27.1s\n",
            "21:\tlearn: 0.4825230\ttotal: 599ms\tremaining: 26.6s\n",
            "22:\tlearn: 0.4739940\ttotal: 624ms\tremaining: 26.5s\n",
            "23:\tlearn: 0.4681606\ttotal: 641ms\tremaining: 26.1s\n",
            "24:\tlearn: 0.4598538\ttotal: 656ms\tremaining: 25.6s\n",
            "25:\tlearn: 0.4516719\ttotal: 667ms\tremaining: 25s\n",
            "26:\tlearn: 0.4453217\ttotal: 676ms\tremaining: 24.4s\n",
            "27:\tlearn: 0.4383940\ttotal: 689ms\tremaining: 23.9s\n",
            "28:\tlearn: 0.4322606\ttotal: 700ms\tremaining: 23.4s\n",
            "29:\tlearn: 0.4251936\ttotal: 708ms\tremaining: 22.9s\n",
            "30:\tlearn: 0.4179450\ttotal: 718ms\tremaining: 22.4s\n",
            "31:\tlearn: 0.4128490\ttotal: 728ms\tremaining: 22s\n",
            "32:\tlearn: 0.4080536\ttotal: 736ms\tremaining: 21.6s\n",
            "33:\tlearn: 0.4013189\ttotal: 747ms\tremaining: 21.2s\n",
            "34:\tlearn: 0.3950454\ttotal: 757ms\tremaining: 20.9s\n",
            "35:\tlearn: 0.3889890\ttotal: 767ms\tremaining: 20.5s\n",
            "36:\tlearn: 0.3826817\ttotal: 775ms\tremaining: 20.2s\n",
            "37:\tlearn: 0.3775739\ttotal: 787ms\tremaining: 19.9s\n",
            "38:\tlearn: 0.3722693\ttotal: 797ms\tremaining: 19.6s\n",
            "39:\tlearn: 0.3665848\ttotal: 806ms\tremaining: 19.4s\n",
            "40:\tlearn: 0.3613396\ttotal: 817ms\tremaining: 19.1s\n",
            "41:\tlearn: 0.3555970\ttotal: 837ms\tremaining: 19.1s\n",
            "42:\tlearn: 0.3499719\ttotal: 854ms\tremaining: 19s\n",
            "43:\tlearn: 0.3459101\ttotal: 878ms\tremaining: 19.1s\n",
            "44:\tlearn: 0.3402028\ttotal: 903ms\tremaining: 19.2s\n",
            "45:\tlearn: 0.3355531\ttotal: 924ms\tremaining: 19.2s\n",
            "46:\tlearn: 0.3312660\ttotal: 944ms\tremaining: 19.1s\n",
            "47:\tlearn: 0.3267230\ttotal: 962ms\tremaining: 19.1s\n",
            "48:\tlearn: 0.3227079\ttotal: 982ms\tremaining: 19.1s\n",
            "49:\tlearn: 0.3185138\ttotal: 1s\tremaining: 19s\n",
            "50:\tlearn: 0.3144261\ttotal: 1.02s\tremaining: 19s\n",
            "51:\tlearn: 0.3103240\ttotal: 1.04s\tremaining: 18.9s\n",
            "52:\tlearn: 0.3062683\ttotal: 1.05s\tremaining: 18.9s\n",
            "53:\tlearn: 0.3024334\ttotal: 1.07s\tremaining: 18.8s\n",
            "54:\tlearn: 0.2991599\ttotal: 1.09s\tremaining: 18.7s\n",
            "55:\tlearn: 0.2956172\ttotal: 1.1s\tremaining: 18.6s\n",
            "56:\tlearn: 0.2917861\ttotal: 1.12s\tremaining: 18.5s\n",
            "57:\tlearn: 0.2875495\ttotal: 1.14s\tremaining: 18.5s\n",
            "58:\tlearn: 0.2835055\ttotal: 1.16s\tremaining: 18.4s\n",
            "59:\tlearn: 0.2798946\ttotal: 1.17s\tremaining: 18.4s\n",
            "60:\tlearn: 0.2760590\ttotal: 1.2s\tremaining: 18.4s\n",
            "61:\tlearn: 0.2725836\ttotal: 1.22s\tremaining: 18.4s\n",
            "62:\tlearn: 0.2692074\ttotal: 1.24s\tremaining: 18.4s\n",
            "63:\tlearn: 0.2655899\ttotal: 1.25s\tremaining: 18.3s\n",
            "64:\tlearn: 0.2621765\ttotal: 1.27s\tremaining: 18.3s\n",
            "65:\tlearn: 0.2590623\ttotal: 1.29s\tremaining: 18.3s\n",
            "66:\tlearn: 0.2558419\ttotal: 1.31s\tremaining: 18.2s\n",
            "67:\tlearn: 0.2524439\ttotal: 1.32s\tremaining: 18.1s\n",
            "68:\tlearn: 0.2495162\ttotal: 1.33s\tremaining: 17.9s\n",
            "69:\tlearn: 0.2467969\ttotal: 1.35s\tremaining: 17.9s\n",
            "70:\tlearn: 0.2436143\ttotal: 1.36s\tremaining: 17.9s\n",
            "71:\tlearn: 0.2405841\ttotal: 1.39s\tremaining: 17.9s\n",
            "72:\tlearn: 0.2375635\ttotal: 1.4s\tremaining: 17.7s\n",
            "73:\tlearn: 0.2348022\ttotal: 1.41s\tremaining: 17.6s\n",
            "74:\tlearn: 0.2317764\ttotal: 1.42s\tremaining: 17.5s\n",
            "75:\tlearn: 0.2294098\ttotal: 1.43s\tremaining: 17.4s\n",
            "76:\tlearn: 0.2265190\ttotal: 1.44s\tremaining: 17.2s\n",
            "77:\tlearn: 0.2238674\ttotal: 1.45s\tremaining: 17.1s\n",
            "78:\tlearn: 0.2210168\ttotal: 1.46s\tremaining: 17s\n",
            "79:\tlearn: 0.2187684\ttotal: 1.48s\tremaining: 17s\n",
            "80:\tlearn: 0.2159665\ttotal: 1.5s\tremaining: 17s\n",
            "81:\tlearn: 0.2130120\ttotal: 1.52s\tremaining: 17s\n",
            "82:\tlearn: 0.2102599\ttotal: 1.54s\tremaining: 17s\n",
            "83:\tlearn: 0.2080026\ttotal: 1.56s\tremaining: 17s\n",
            "84:\tlearn: 0.2051810\ttotal: 1.58s\tremaining: 17s\n",
            "85:\tlearn: 0.2028046\ttotal: 1.6s\tremaining: 17.1s\n",
            "86:\tlearn: 0.2006244\ttotal: 1.63s\tremaining: 17.1s\n",
            "87:\tlearn: 0.1984008\ttotal: 1.65s\tremaining: 17.1s\n",
            "88:\tlearn: 0.1961487\ttotal: 1.67s\tremaining: 17.1s\n",
            "89:\tlearn: 0.1941267\ttotal: 1.68s\tremaining: 17s\n",
            "90:\tlearn: 0.1922011\ttotal: 1.69s\tremaining: 16.9s\n",
            "91:\tlearn: 0.1899213\ttotal: 1.7s\tremaining: 16.8s\n",
            "92:\tlearn: 0.1878445\ttotal: 1.71s\tremaining: 16.7s\n",
            "93:\tlearn: 0.1859494\ttotal: 1.72s\tremaining: 16.6s\n",
            "94:\tlearn: 0.1837461\ttotal: 1.73s\tremaining: 16.5s\n",
            "95:\tlearn: 0.1817467\ttotal: 1.74s\tremaining: 16.4s\n",
            "96:\tlearn: 0.1798949\ttotal: 1.76s\tremaining: 16.4s\n",
            "97:\tlearn: 0.1782303\ttotal: 1.78s\tremaining: 16.4s\n",
            "98:\tlearn: 0.1769184\ttotal: 1.81s\tremaining: 16.4s\n",
            "99:\tlearn: 0.1754444\ttotal: 1.82s\tremaining: 16.4s\n",
            "100:\tlearn: 0.1732113\ttotal: 1.84s\tremaining: 16.4s\n",
            "101:\tlearn: 0.1714116\ttotal: 1.86s\tremaining: 16.4s\n",
            "102:\tlearn: 0.1695568\ttotal: 1.88s\tremaining: 16.4s\n",
            "103:\tlearn: 0.1677687\ttotal: 1.89s\tremaining: 16.3s\n",
            "104:\tlearn: 0.1658949\ttotal: 1.9s\tremaining: 16.2s\n",
            "105:\tlearn: 0.1645744\ttotal: 1.91s\tremaining: 16.1s\n",
            "106:\tlearn: 0.1629330\ttotal: 1.92s\tremaining: 16s\n",
            "107:\tlearn: 0.1610750\ttotal: 1.93s\tremaining: 16s\n",
            "108:\tlearn: 0.1594110\ttotal: 1.96s\tremaining: 16s\n",
            "109:\tlearn: 0.1580596\ttotal: 1.98s\tremaining: 16s\n",
            "110:\tlearn: 0.1563669\ttotal: 1.99s\tremaining: 15.9s\n",
            "111:\tlearn: 0.1548170\ttotal: 2s\tremaining: 15.8s\n",
            "112:\tlearn: 0.1531156\ttotal: 2.02s\tremaining: 15.9s\n",
            "113:\tlearn: 0.1516886\ttotal: 2.04s\tremaining: 15.8s\n",
            "114:\tlearn: 0.1501054\ttotal: 2.05s\tremaining: 15.8s\n",
            "115:\tlearn: 0.1484813\ttotal: 2.06s\tremaining: 15.7s\n",
            "116:\tlearn: 0.1472183\ttotal: 2.07s\tremaining: 15.6s\n",
            "117:\tlearn: 0.1459647\ttotal: 2.08s\tremaining: 15.6s\n",
            "118:\tlearn: 0.1444379\ttotal: 2.1s\tremaining: 15.5s\n",
            "119:\tlearn: 0.1432663\ttotal: 2.12s\tremaining: 15.6s\n",
            "120:\tlearn: 0.1420071\ttotal: 2.14s\tremaining: 15.6s\n",
            "121:\tlearn: 0.1404758\ttotal: 2.16s\tremaining: 15.6s\n",
            "122:\tlearn: 0.1390195\ttotal: 2.18s\tremaining: 15.6s\n",
            "123:\tlearn: 0.1378147\ttotal: 2.2s\tremaining: 15.6s\n",
            "124:\tlearn: 0.1365820\ttotal: 2.22s\tremaining: 15.6s\n",
            "125:\tlearn: 0.1354247\ttotal: 2.24s\tremaining: 15.5s\n",
            "126:\tlearn: 0.1344274\ttotal: 2.26s\tremaining: 15.6s\n",
            "127:\tlearn: 0.1332096\ttotal: 2.29s\tremaining: 15.6s\n",
            "128:\tlearn: 0.1319121\ttotal: 2.31s\tremaining: 15.6s\n",
            "129:\tlearn: 0.1306053\ttotal: 2.32s\tremaining: 15.6s\n",
            "130:\tlearn: 0.1296384\ttotal: 2.34s\tremaining: 15.5s\n",
            "131:\tlearn: 0.1283361\ttotal: 2.36s\tremaining: 15.5s\n",
            "132:\tlearn: 0.1272497\ttotal: 2.38s\tremaining: 15.5s\n",
            "133:\tlearn: 0.1263281\ttotal: 2.4s\tremaining: 15.5s\n",
            "134:\tlearn: 0.1250785\ttotal: 2.42s\tremaining: 15.5s\n",
            "135:\tlearn: 0.1239636\ttotal: 2.43s\tremaining: 15.4s\n",
            "136:\tlearn: 0.1226881\ttotal: 2.44s\tremaining: 15.4s\n",
            "137:\tlearn: 0.1215555\ttotal: 2.45s\tremaining: 15.3s\n",
            "138:\tlearn: 0.1202647\ttotal: 2.46s\tremaining: 15.2s\n",
            "139:\tlearn: 0.1195065\ttotal: 2.47s\tremaining: 15.2s\n",
            "140:\tlearn: 0.1185034\ttotal: 2.48s\tremaining: 15.1s\n",
            "141:\tlearn: 0.1177685\ttotal: 2.49s\tremaining: 15s\n",
            "142:\tlearn: 0.1166990\ttotal: 2.5s\tremaining: 15s\n",
            "143:\tlearn: 0.1158034\ttotal: 2.51s\tremaining: 14.9s\n",
            "144:\tlearn: 0.1147943\ttotal: 2.52s\tremaining: 14.9s\n",
            "145:\tlearn: 0.1137357\ttotal: 2.53s\tremaining: 14.8s\n",
            "146:\tlearn: 0.1127635\ttotal: 2.54s\tremaining: 14.7s\n",
            "147:\tlearn: 0.1116818\ttotal: 2.55s\tremaining: 14.7s\n",
            "148:\tlearn: 0.1107587\ttotal: 2.57s\tremaining: 14.7s\n",
            "149:\tlearn: 0.1097017\ttotal: 2.59s\tremaining: 14.7s\n",
            "150:\tlearn: 0.1089848\ttotal: 2.61s\tremaining: 14.7s\n",
            "151:\tlearn: 0.1082867\ttotal: 2.63s\tremaining: 14.7s\n",
            "152:\tlearn: 0.1074287\ttotal: 2.65s\tremaining: 14.7s\n",
            "153:\tlearn: 0.1065225\ttotal: 2.65s\tremaining: 14.6s\n",
            "154:\tlearn: 0.1056695\ttotal: 2.67s\tremaining: 14.5s\n",
            "155:\tlearn: 0.1047647\ttotal: 2.67s\tremaining: 14.5s\n",
            "156:\tlearn: 0.1039409\ttotal: 2.68s\tremaining: 14.4s\n",
            "157:\tlearn: 0.1032636\ttotal: 2.69s\tremaining: 14.3s\n",
            "158:\tlearn: 0.1022971\ttotal: 2.7s\tremaining: 14.3s\n",
            "159:\tlearn: 0.1016747\ttotal: 2.7s\tremaining: 14.2s\n",
            "160:\tlearn: 0.1008931\ttotal: 2.71s\tremaining: 14.1s\n",
            "161:\tlearn: 0.1002546\ttotal: 2.72s\tremaining: 14.1s\n",
            "162:\tlearn: 0.0995413\ttotal: 2.73s\tremaining: 14s\n",
            "163:\tlearn: 0.0986669\ttotal: 2.73s\tremaining: 13.9s\n",
            "164:\tlearn: 0.0980058\ttotal: 2.74s\tremaining: 13.9s\n",
            "165:\tlearn: 0.0973939\ttotal: 2.75s\tremaining: 13.8s\n",
            "166:\tlearn: 0.0967388\ttotal: 2.75s\tremaining: 13.7s\n",
            "167:\tlearn: 0.0961089\ttotal: 2.76s\tremaining: 13.7s\n",
            "168:\tlearn: 0.0954381\ttotal: 2.77s\tremaining: 13.6s\n",
            "169:\tlearn: 0.0946510\ttotal: 2.78s\tremaining: 13.6s\n",
            "170:\tlearn: 0.0939177\ttotal: 2.78s\tremaining: 13.5s\n",
            "171:\tlearn: 0.0932187\ttotal: 2.79s\tremaining: 13.4s\n",
            "172:\tlearn: 0.0924643\ttotal: 2.8s\tremaining: 13.4s\n",
            "173:\tlearn: 0.0917815\ttotal: 2.81s\tremaining: 13.3s\n",
            "174:\tlearn: 0.0912301\ttotal: 2.81s\tremaining: 13.3s\n",
            "175:\tlearn: 0.0905638\ttotal: 2.82s\tremaining: 13.2s\n",
            "176:\tlearn: 0.0901109\ttotal: 2.83s\tremaining: 13.2s\n",
            "177:\tlearn: 0.0893600\ttotal: 2.84s\tremaining: 13.1s\n",
            "178:\tlearn: 0.0887199\ttotal: 2.84s\tremaining: 13s\n",
            "179:\tlearn: 0.0880829\ttotal: 2.85s\tremaining: 13s\n",
            "180:\tlearn: 0.0876165\ttotal: 2.86s\tremaining: 12.9s\n",
            "181:\tlearn: 0.0868924\ttotal: 2.87s\tremaining: 12.9s\n",
            "182:\tlearn: 0.0862167\ttotal: 2.87s\tremaining: 12.8s\n",
            "183:\tlearn: 0.0856086\ttotal: 2.88s\tremaining: 12.8s\n",
            "184:\tlearn: 0.0849957\ttotal: 2.89s\tremaining: 12.7s\n",
            "185:\tlearn: 0.0844171\ttotal: 2.9s\tremaining: 12.7s\n",
            "186:\tlearn: 0.0839471\ttotal: 2.9s\tremaining: 12.6s\n",
            "187:\tlearn: 0.0834619\ttotal: 2.91s\tremaining: 12.6s\n",
            "188:\tlearn: 0.0829025\ttotal: 2.92s\tremaining: 12.5s\n",
            "189:\tlearn: 0.0822734\ttotal: 2.93s\tremaining: 12.5s\n",
            "190:\tlearn: 0.0816653\ttotal: 2.93s\tremaining: 12.4s\n",
            "191:\tlearn: 0.0810884\ttotal: 2.94s\tremaining: 12.4s\n",
            "192:\tlearn: 0.0806231\ttotal: 2.95s\tremaining: 12.3s\n",
            "193:\tlearn: 0.0800344\ttotal: 2.95s\tremaining: 12.3s\n",
            "194:\tlearn: 0.0794511\ttotal: 2.96s\tremaining: 12.2s\n",
            "195:\tlearn: 0.0789261\ttotal: 2.97s\tremaining: 12.2s\n",
            "196:\tlearn: 0.0784176\ttotal: 2.98s\tremaining: 12.1s\n",
            "197:\tlearn: 0.0778596\ttotal: 2.98s\tremaining: 12.1s\n",
            "198:\tlearn: 0.0773892\ttotal: 2.99s\tremaining: 12s\n",
            "199:\tlearn: 0.0768893\ttotal: 3s\tremaining: 12s\n",
            "200:\tlearn: 0.0763297\ttotal: 3s\tremaining: 11.9s\n",
            "201:\tlearn: 0.0758182\ttotal: 3.01s\tremaining: 11.9s\n",
            "202:\tlearn: 0.0752046\ttotal: 3.02s\tremaining: 11.9s\n",
            "203:\tlearn: 0.0748098\ttotal: 3.03s\tremaining: 11.8s\n",
            "204:\tlearn: 0.0743592\ttotal: 3.03s\tremaining: 11.8s\n",
            "205:\tlearn: 0.0738834\ttotal: 3.04s\tremaining: 11.7s\n",
            "206:\tlearn: 0.0735350\ttotal: 3.05s\tremaining: 11.7s\n",
            "207:\tlearn: 0.0730304\ttotal: 3.06s\tremaining: 11.6s\n",
            "208:\tlearn: 0.0726251\ttotal: 3.06s\tremaining: 11.6s\n",
            "209:\tlearn: 0.0720993\ttotal: 3.07s\tremaining: 11.5s\n",
            "210:\tlearn: 0.0716562\ttotal: 3.08s\tremaining: 11.5s\n",
            "211:\tlearn: 0.0713121\ttotal: 3.08s\tremaining: 11.5s\n",
            "212:\tlearn: 0.0708855\ttotal: 3.1s\tremaining: 11.4s\n",
            "213:\tlearn: 0.0703749\ttotal: 3.1s\tremaining: 11.4s\n",
            "214:\tlearn: 0.0699434\ttotal: 3.11s\tremaining: 11.4s\n",
            "215:\tlearn: 0.0696445\ttotal: 3.12s\tremaining: 11.3s\n",
            "216:\tlearn: 0.0692420\ttotal: 3.13s\tremaining: 11.3s\n",
            "217:\tlearn: 0.0689260\ttotal: 3.13s\tremaining: 11.2s\n",
            "218:\tlearn: 0.0686458\ttotal: 3.14s\tremaining: 11.2s\n",
            "219:\tlearn: 0.0683420\ttotal: 3.15s\tremaining: 11.2s\n",
            "220:\tlearn: 0.0681149\ttotal: 3.15s\tremaining: 11.1s\n",
            "221:\tlearn: 0.0677139\ttotal: 3.16s\tremaining: 11.1s\n",
            "222:\tlearn: 0.0672142\ttotal: 3.17s\tremaining: 11s\n",
            "223:\tlearn: 0.0668488\ttotal: 3.18s\tremaining: 11s\n",
            "224:\tlearn: 0.0664175\ttotal: 3.18s\tremaining: 11s\n",
            "225:\tlearn: 0.0660819\ttotal: 3.19s\tremaining: 10.9s\n",
            "226:\tlearn: 0.0656830\ttotal: 3.2s\tremaining: 10.9s\n",
            "227:\tlearn: 0.0653443\ttotal: 3.21s\tremaining: 10.9s\n",
            "228:\tlearn: 0.0649530\ttotal: 3.21s\tremaining: 10.8s\n",
            "229:\tlearn: 0.0644422\ttotal: 3.22s\tremaining: 10.8s\n",
            "230:\tlearn: 0.0641115\ttotal: 3.23s\tremaining: 10.7s\n",
            "231:\tlearn: 0.0637383\ttotal: 3.24s\tremaining: 10.7s\n",
            "232:\tlearn: 0.0633377\ttotal: 3.24s\tremaining: 10.7s\n",
            "233:\tlearn: 0.0629264\ttotal: 3.25s\tremaining: 10.6s\n",
            "234:\tlearn: 0.0625493\ttotal: 3.26s\tremaining: 10.6s\n",
            "235:\tlearn: 0.0621819\ttotal: 3.27s\tremaining: 10.6s\n",
            "236:\tlearn: 0.0618321\ttotal: 3.27s\tremaining: 10.5s\n",
            "237:\tlearn: 0.0614378\ttotal: 3.28s\tremaining: 10.5s\n",
            "238:\tlearn: 0.0610668\ttotal: 3.29s\tremaining: 10.5s\n",
            "239:\tlearn: 0.0607255\ttotal: 3.3s\tremaining: 10.4s\n",
            "240:\tlearn: 0.0604857\ttotal: 3.3s\tremaining: 10.4s\n",
            "241:\tlearn: 0.0601160\ttotal: 3.31s\tremaining: 10.4s\n",
            "242:\tlearn: 0.0597690\ttotal: 3.32s\tremaining: 10.3s\n",
            "243:\tlearn: 0.0595826\ttotal: 3.33s\tremaining: 10.3s\n",
            "244:\tlearn: 0.0592354\ttotal: 3.33s\tremaining: 10.3s\n",
            "245:\tlearn: 0.0589146\ttotal: 3.34s\tremaining: 10.2s\n",
            "246:\tlearn: 0.0585960\ttotal: 3.35s\tremaining: 10.2s\n",
            "247:\tlearn: 0.0583647\ttotal: 3.36s\tremaining: 10.2s\n",
            "248:\tlearn: 0.0581086\ttotal: 3.36s\tremaining: 10.1s\n",
            "249:\tlearn: 0.0578920\ttotal: 3.37s\tremaining: 10.1s\n",
            "250:\tlearn: 0.0575696\ttotal: 3.38s\tremaining: 10.1s\n",
            "251:\tlearn: 0.0573225\ttotal: 3.38s\tremaining: 10s\n",
            "252:\tlearn: 0.0570462\ttotal: 3.4s\tremaining: 10s\n",
            "253:\tlearn: 0.0567400\ttotal: 3.42s\tremaining: 10s\n",
            "254:\tlearn: 0.0564744\ttotal: 3.43s\tremaining: 10s\n",
            "255:\tlearn: 0.0561352\ttotal: 3.44s\tremaining: 9.99s\n",
            "256:\tlearn: 0.0558480\ttotal: 3.44s\tremaining: 9.96s\n",
            "257:\tlearn: 0.0556567\ttotal: 3.45s\tremaining: 9.93s\n",
            "258:\tlearn: 0.0553692\ttotal: 3.46s\tremaining: 9.9s\n",
            "259:\tlearn: 0.0551013\ttotal: 3.47s\tremaining: 9.87s\n",
            "260:\tlearn: 0.0548185\ttotal: 3.47s\tremaining: 9.84s\n",
            "261:\tlearn: 0.0545379\ttotal: 3.48s\tremaining: 9.8s\n",
            "262:\tlearn: 0.0541706\ttotal: 3.49s\tremaining: 9.78s\n",
            "263:\tlearn: 0.0538881\ttotal: 3.5s\tremaining: 9.75s\n",
            "264:\tlearn: 0.0536361\ttotal: 3.51s\tremaining: 9.73s\n",
            "265:\tlearn: 0.0534204\ttotal: 3.51s\tremaining: 9.7s\n",
            "266:\tlearn: 0.0531378\ttotal: 3.52s\tremaining: 9.67s\n",
            "267:\tlearn: 0.0528651\ttotal: 3.53s\tremaining: 9.64s\n",
            "268:\tlearn: 0.0525707\ttotal: 3.54s\tremaining: 9.62s\n",
            "269:\tlearn: 0.0523641\ttotal: 3.54s\tremaining: 9.59s\n",
            "270:\tlearn: 0.0521404\ttotal: 3.55s\tremaining: 9.56s\n",
            "271:\tlearn: 0.0518770\ttotal: 3.56s\tremaining: 9.53s\n",
            "272:\tlearn: 0.0516577\ttotal: 3.57s\tremaining: 9.5s\n",
            "273:\tlearn: 0.0514821\ttotal: 3.57s\tremaining: 9.47s\n",
            "274:\tlearn: 0.0512464\ttotal: 3.58s\tremaining: 9.44s\n",
            "275:\tlearn: 0.0509962\ttotal: 3.59s\tremaining: 9.41s\n",
            "276:\tlearn: 0.0507165\ttotal: 3.6s\tremaining: 9.39s\n",
            "277:\tlearn: 0.0505348\ttotal: 3.6s\tremaining: 9.36s\n",
            "278:\tlearn: 0.0502466\ttotal: 3.61s\tremaining: 9.33s\n",
            "279:\tlearn: 0.0500635\ttotal: 3.62s\tremaining: 9.3s\n",
            "280:\tlearn: 0.0498854\ttotal: 3.63s\tremaining: 9.28s\n",
            "281:\tlearn: 0.0496705\ttotal: 3.63s\tremaining: 9.25s\n",
            "282:\tlearn: 0.0494572\ttotal: 3.64s\tremaining: 9.22s\n",
            "283:\tlearn: 0.0491972\ttotal: 3.65s\tremaining: 9.2s\n",
            "284:\tlearn: 0.0490224\ttotal: 3.66s\tremaining: 9.18s\n",
            "285:\tlearn: 0.0488203\ttotal: 3.66s\tremaining: 9.15s\n",
            "286:\tlearn: 0.0486274\ttotal: 3.67s\tremaining: 9.12s\n",
            "287:\tlearn: 0.0484645\ttotal: 3.68s\tremaining: 9.1s\n",
            "288:\tlearn: 0.0481984\ttotal: 3.69s\tremaining: 9.07s\n",
            "289:\tlearn: 0.0479065\ttotal: 3.69s\tremaining: 9.04s\n",
            "290:\tlearn: 0.0476493\ttotal: 3.7s\tremaining: 9.03s\n",
            "291:\tlearn: 0.0474691\ttotal: 3.71s\tremaining: 9s\n",
            "292:\tlearn: 0.0472338\ttotal: 3.72s\tremaining: 8.97s\n",
            "293:\tlearn: 0.0470095\ttotal: 3.73s\tremaining: 8.95s\n",
            "294:\tlearn: 0.0468055\ttotal: 3.73s\tremaining: 8.92s\n",
            "295:\tlearn: 0.0466001\ttotal: 3.74s\tremaining: 8.9s\n",
            "296:\tlearn: 0.0463344\ttotal: 3.75s\tremaining: 8.87s\n",
            "297:\tlearn: 0.0461224\ttotal: 3.75s\tremaining: 8.85s\n",
            "298:\tlearn: 0.0458670\ttotal: 3.76s\tremaining: 8.82s\n",
            "299:\tlearn: 0.0456651\ttotal: 3.77s\tremaining: 8.8s\n",
            "300:\tlearn: 0.0454280\ttotal: 3.78s\tremaining: 8.77s\n",
            "301:\tlearn: 0.0452608\ttotal: 3.78s\tremaining: 8.75s\n",
            "302:\tlearn: 0.0450761\ttotal: 3.79s\tremaining: 8.72s\n",
            "303:\tlearn: 0.0449004\ttotal: 3.8s\tremaining: 8.7s\n",
            "304:\tlearn: 0.0447369\ttotal: 3.81s\tremaining: 8.67s\n",
            "305:\tlearn: 0.0445451\ttotal: 3.81s\tremaining: 8.65s\n",
            "306:\tlearn: 0.0442553\ttotal: 3.82s\tremaining: 8.63s\n",
            "307:\tlearn: 0.0441504\ttotal: 3.83s\tremaining: 8.6s\n",
            "308:\tlearn: 0.0439608\ttotal: 3.84s\tremaining: 8.58s\n",
            "309:\tlearn: 0.0437141\ttotal: 3.85s\tremaining: 8.56s\n",
            "310:\tlearn: 0.0435130\ttotal: 3.85s\tremaining: 8.54s\n",
            "311:\tlearn: 0.0433887\ttotal: 3.86s\tremaining: 8.51s\n",
            "312:\tlearn: 0.0431613\ttotal: 3.87s\tremaining: 8.49s\n",
            "313:\tlearn: 0.0429998\ttotal: 3.87s\tremaining: 8.46s\n",
            "314:\tlearn: 0.0427830\ttotal: 3.88s\tremaining: 8.44s\n",
            "315:\tlearn: 0.0426066\ttotal: 3.89s\tremaining: 8.42s\n",
            "316:\tlearn: 0.0424319\ttotal: 3.9s\tremaining: 8.39s\n",
            "317:\tlearn: 0.0422896\ttotal: 3.91s\tremaining: 8.38s\n",
            "318:\tlearn: 0.0421821\ttotal: 3.91s\tremaining: 8.36s\n",
            "319:\tlearn: 0.0419479\ttotal: 3.92s\tremaining: 8.33s\n",
            "320:\tlearn: 0.0418013\ttotal: 3.93s\tremaining: 8.31s\n",
            "321:\tlearn: 0.0416475\ttotal: 3.94s\tremaining: 8.29s\n",
            "322:\tlearn: 0.0414538\ttotal: 3.94s\tremaining: 8.27s\n",
            "323:\tlearn: 0.0413163\ttotal: 3.95s\tremaining: 8.24s\n",
            "324:\tlearn: 0.0411425\ttotal: 3.96s\tremaining: 8.22s\n",
            "325:\tlearn: 0.0409935\ttotal: 3.96s\tremaining: 8.2s\n",
            "326:\tlearn: 0.0408735\ttotal: 3.97s\tremaining: 8.18s\n",
            "327:\tlearn: 0.0406891\ttotal: 3.98s\tremaining: 8.15s\n",
            "328:\tlearn: 0.0405048\ttotal: 3.99s\tremaining: 8.13s\n",
            "329:\tlearn: 0.0403247\ttotal: 3.99s\tremaining: 8.11s\n",
            "330:\tlearn: 0.0401289\ttotal: 4s\tremaining: 8.09s\n",
            "331:\tlearn: 0.0399708\ttotal: 4.01s\tremaining: 8.07s\n",
            "332:\tlearn: 0.0397860\ttotal: 4.02s\tremaining: 8.04s\n",
            "333:\tlearn: 0.0396880\ttotal: 4.02s\tremaining: 8.02s\n",
            "334:\tlearn: 0.0395451\ttotal: 4.03s\tremaining: 8s\n",
            "335:\tlearn: 0.0394162\ttotal: 4.04s\tremaining: 7.98s\n",
            "336:\tlearn: 0.0392935\ttotal: 4.05s\tremaining: 7.96s\n",
            "337:\tlearn: 0.0391978\ttotal: 4.05s\tremaining: 7.94s\n",
            "338:\tlearn: 0.0390372\ttotal: 4.06s\tremaining: 7.92s\n",
            "339:\tlearn: 0.0388886\ttotal: 4.07s\tremaining: 7.9s\n",
            "340:\tlearn: 0.0386839\ttotal: 4.08s\tremaining: 7.88s\n",
            "341:\tlearn: 0.0385030\ttotal: 4.08s\tremaining: 7.86s\n",
            "342:\tlearn: 0.0383323\ttotal: 4.09s\tremaining: 7.84s\n",
            "343:\tlearn: 0.0381266\ttotal: 4.1s\tremaining: 7.82s\n",
            "344:\tlearn: 0.0379941\ttotal: 4.11s\tremaining: 7.8s\n",
            "345:\tlearn: 0.0378596\ttotal: 4.12s\tremaining: 7.78s\n",
            "346:\tlearn: 0.0376756\ttotal: 4.13s\tremaining: 7.77s\n",
            "347:\tlearn: 0.0375056\ttotal: 4.13s\tremaining: 7.75s\n",
            "348:\tlearn: 0.0373644\ttotal: 4.14s\tremaining: 7.73s\n",
            "349:\tlearn: 0.0372630\ttotal: 4.15s\tremaining: 7.71s\n",
            "350:\tlearn: 0.0371406\ttotal: 4.16s\tremaining: 7.69s\n",
            "351:\tlearn: 0.0370251\ttotal: 4.17s\tremaining: 7.67s\n",
            "352:\tlearn: 0.0368695\ttotal: 4.17s\tremaining: 7.65s\n",
            "353:\tlearn: 0.0367344\ttotal: 4.18s\tremaining: 7.63s\n",
            "354:\tlearn: 0.0365610\ttotal: 4.19s\tremaining: 7.61s\n",
            "355:\tlearn: 0.0363499\ttotal: 4.2s\tremaining: 7.59s\n",
            "356:\tlearn: 0.0362143\ttotal: 4.2s\tremaining: 7.57s\n",
            "357:\tlearn: 0.0360737\ttotal: 4.21s\tremaining: 7.55s\n",
            "358:\tlearn: 0.0359380\ttotal: 4.22s\tremaining: 7.53s\n",
            "359:\tlearn: 0.0357559\ttotal: 4.23s\tremaining: 7.52s\n",
            "360:\tlearn: 0.0355861\ttotal: 4.24s\tremaining: 7.5s\n",
            "361:\tlearn: 0.0354537\ttotal: 4.24s\tremaining: 7.48s\n",
            "362:\tlearn: 0.0353881\ttotal: 4.25s\tremaining: 7.46s\n",
            "363:\tlearn: 0.0353112\ttotal: 4.26s\tremaining: 7.44s\n",
            "364:\tlearn: 0.0351368\ttotal: 4.27s\tremaining: 7.42s\n",
            "365:\tlearn: 0.0349901\ttotal: 4.27s\tremaining: 7.4s\n",
            "366:\tlearn: 0.0348519\ttotal: 4.28s\tremaining: 7.38s\n",
            "367:\tlearn: 0.0346921\ttotal: 4.29s\tremaining: 7.36s\n",
            "368:\tlearn: 0.0345860\ttotal: 4.29s\tremaining: 7.35s\n",
            "369:\tlearn: 0.0344597\ttotal: 4.3s\tremaining: 7.33s\n",
            "370:\tlearn: 0.0342967\ttotal: 4.31s\tremaining: 7.31s\n",
            "371:\tlearn: 0.0341368\ttotal: 4.32s\tremaining: 7.29s\n",
            "372:\tlearn: 0.0339922\ttotal: 4.33s\tremaining: 7.28s\n",
            "373:\tlearn: 0.0338986\ttotal: 4.33s\tremaining: 7.26s\n",
            "374:\tlearn: 0.0338026\ttotal: 4.34s\tremaining: 7.24s\n",
            "375:\tlearn: 0.0336879\ttotal: 4.35s\tremaining: 7.22s\n",
            "376:\tlearn: 0.0335493\ttotal: 4.36s\tremaining: 7.2s\n",
            "377:\tlearn: 0.0334549\ttotal: 4.36s\tremaining: 7.18s\n",
            "378:\tlearn: 0.0333474\ttotal: 4.37s\tremaining: 7.16s\n",
            "379:\tlearn: 0.0332058\ttotal: 4.38s\tremaining: 7.14s\n",
            "380:\tlearn: 0.0330686\ttotal: 4.39s\tremaining: 7.13s\n",
            "381:\tlearn: 0.0329581\ttotal: 4.39s\tremaining: 7.11s\n",
            "382:\tlearn: 0.0328500\ttotal: 4.4s\tremaining: 7.09s\n",
            "383:\tlearn: 0.0326983\ttotal: 4.42s\tremaining: 7.08s\n",
            "384:\tlearn: 0.0325689\ttotal: 4.43s\tremaining: 7.08s\n",
            "385:\tlearn: 0.0324352\ttotal: 4.44s\tremaining: 7.07s\n",
            "386:\tlearn: 0.0323163\ttotal: 4.45s\tremaining: 7.05s\n",
            "387:\tlearn: 0.0322134\ttotal: 4.46s\tremaining: 7.03s\n",
            "388:\tlearn: 0.0321061\ttotal: 4.46s\tremaining: 7.01s\n",
            "389:\tlearn: 0.0320167\ttotal: 4.47s\tremaining: 7s\n",
            "390:\tlearn: 0.0318672\ttotal: 4.48s\tremaining: 6.98s\n",
            "391:\tlearn: 0.0317563\ttotal: 4.49s\tremaining: 6.96s\n",
            "392:\tlearn: 0.0316617\ttotal: 4.49s\tremaining: 6.94s\n",
            "393:\tlearn: 0.0315178\ttotal: 4.5s\tremaining: 6.92s\n",
            "394:\tlearn: 0.0314145\ttotal: 4.51s\tremaining: 6.91s\n",
            "395:\tlearn: 0.0312479\ttotal: 4.52s\tremaining: 6.89s\n",
            "396:\tlearn: 0.0311862\ttotal: 4.53s\tremaining: 6.88s\n",
            "397:\tlearn: 0.0311156\ttotal: 4.54s\tremaining: 6.86s\n",
            "398:\tlearn: 0.0310657\ttotal: 4.54s\tremaining: 6.84s\n",
            "399:\tlearn: 0.0309602\ttotal: 4.55s\tremaining: 6.82s\n",
            "400:\tlearn: 0.0308702\ttotal: 4.56s\tremaining: 6.81s\n",
            "401:\tlearn: 0.0307495\ttotal: 4.56s\tremaining: 6.79s\n",
            "402:\tlearn: 0.0306671\ttotal: 4.57s\tremaining: 6.77s\n",
            "403:\tlearn: 0.0305567\ttotal: 4.58s\tremaining: 6.75s\n",
            "404:\tlearn: 0.0304327\ttotal: 4.58s\tremaining: 6.74s\n",
            "405:\tlearn: 0.0303333\ttotal: 4.59s\tremaining: 6.72s\n",
            "406:\tlearn: 0.0302721\ttotal: 4.6s\tremaining: 6.7s\n",
            "407:\tlearn: 0.0301456\ttotal: 4.61s\tremaining: 6.68s\n",
            "408:\tlearn: 0.0300373\ttotal: 4.61s\tremaining: 6.67s\n",
            "409:\tlearn: 0.0299067\ttotal: 4.62s\tremaining: 6.65s\n",
            "410:\tlearn: 0.0298211\ttotal: 4.63s\tremaining: 6.64s\n",
            "411:\tlearn: 0.0296995\ttotal: 4.64s\tremaining: 6.62s\n",
            "412:\tlearn: 0.0296797\ttotal: 4.65s\tremaining: 6.6s\n",
            "413:\tlearn: 0.0295980\ttotal: 4.65s\tremaining: 6.59s\n",
            "414:\tlearn: 0.0295294\ttotal: 4.66s\tremaining: 6.57s\n",
            "415:\tlearn: 0.0294400\ttotal: 4.67s\tremaining: 6.55s\n",
            "416:\tlearn: 0.0293368\ttotal: 4.67s\tremaining: 6.54s\n",
            "417:\tlearn: 0.0292305\ttotal: 4.68s\tremaining: 6.52s\n",
            "418:\tlearn: 0.0291223\ttotal: 4.69s\tremaining: 6.5s\n",
            "419:\tlearn: 0.0290331\ttotal: 4.7s\tremaining: 6.49s\n",
            "420:\tlearn: 0.0289483\ttotal: 4.7s\tremaining: 6.47s\n",
            "421:\tlearn: 0.0288606\ttotal: 4.71s\tremaining: 6.45s\n",
            "422:\tlearn: 0.0287444\ttotal: 4.72s\tremaining: 6.44s\n",
            "423:\tlearn: 0.0286838\ttotal: 4.73s\tremaining: 6.42s\n",
            "424:\tlearn: 0.0286213\ttotal: 4.74s\tremaining: 6.41s\n",
            "425:\tlearn: 0.0285211\ttotal: 4.75s\tremaining: 6.39s\n",
            "426:\tlearn: 0.0284163\ttotal: 4.75s\tremaining: 6.38s\n",
            "427:\tlearn: 0.0283277\ttotal: 4.76s\tremaining: 6.36s\n",
            "428:\tlearn: 0.0282479\ttotal: 4.77s\tremaining: 6.35s\n",
            "429:\tlearn: 0.0281730\ttotal: 4.78s\tremaining: 6.33s\n",
            "430:\tlearn: 0.0281112\ttotal: 4.78s\tremaining: 6.31s\n",
            "431:\tlearn: 0.0280359\ttotal: 4.79s\tremaining: 6.3s\n",
            "432:\tlearn: 0.0279756\ttotal: 4.8s\tremaining: 6.28s\n",
            "433:\tlearn: 0.0278745\ttotal: 4.8s\tremaining: 6.27s\n",
            "434:\tlearn: 0.0278053\ttotal: 4.81s\tremaining: 6.25s\n",
            "435:\tlearn: 0.0277279\ttotal: 4.82s\tremaining: 6.23s\n",
            "436:\tlearn: 0.0276286\ttotal: 4.83s\tremaining: 6.22s\n",
            "437:\tlearn: 0.0275388\ttotal: 4.83s\tremaining: 6.2s\n",
            "438:\tlearn: 0.0274451\ttotal: 4.84s\tremaining: 6.19s\n",
            "439:\tlearn: 0.0273212\ttotal: 4.85s\tremaining: 6.17s\n",
            "440:\tlearn: 0.0272539\ttotal: 4.86s\tremaining: 6.16s\n",
            "441:\tlearn: 0.0271812\ttotal: 4.86s\tremaining: 6.14s\n",
            "442:\tlearn: 0.0271049\ttotal: 4.87s\tremaining: 6.12s\n",
            "443:\tlearn: 0.0270360\ttotal: 4.88s\tremaining: 6.11s\n",
            "444:\tlearn: 0.0269677\ttotal: 4.88s\tremaining: 6.09s\n",
            "445:\tlearn: 0.0268982\ttotal: 4.89s\tremaining: 6.08s\n",
            "446:\tlearn: 0.0267954\ttotal: 4.9s\tremaining: 6.06s\n",
            "447:\tlearn: 0.0267023\ttotal: 4.91s\tremaining: 6.04s\n",
            "448:\tlearn: 0.0266435\ttotal: 4.91s\tremaining: 6.03s\n",
            "449:\tlearn: 0.0265503\ttotal: 4.92s\tremaining: 6.02s\n",
            "450:\tlearn: 0.0264504\ttotal: 4.93s\tremaining: 6s\n",
            "451:\tlearn: 0.0263469\ttotal: 4.94s\tremaining: 5.99s\n",
            "452:\tlearn: 0.0262578\ttotal: 4.95s\tremaining: 5.97s\n",
            "453:\tlearn: 0.0261450\ttotal: 4.95s\tremaining: 5.96s\n",
            "454:\tlearn: 0.0260965\ttotal: 4.96s\tremaining: 5.94s\n",
            "455:\tlearn: 0.0259897\ttotal: 4.97s\tremaining: 5.92s\n",
            "456:\tlearn: 0.0259000\ttotal: 4.97s\tremaining: 5.91s\n",
            "457:\tlearn: 0.0257970\ttotal: 4.98s\tremaining: 5.89s\n",
            "458:\tlearn: 0.0257417\ttotal: 4.99s\tremaining: 5.88s\n",
            "459:\tlearn: 0.0256950\ttotal: 5s\tremaining: 5.86s\n",
            "460:\tlearn: 0.0256034\ttotal: 5s\tremaining: 5.85s\n",
            "461:\tlearn: 0.0255464\ttotal: 5.01s\tremaining: 5.83s\n",
            "462:\tlearn: 0.0254625\ttotal: 5.02s\tremaining: 5.82s\n",
            "463:\tlearn: 0.0253721\ttotal: 5.02s\tremaining: 5.8s\n",
            "464:\tlearn: 0.0253158\ttotal: 5.03s\tremaining: 5.79s\n",
            "465:\tlearn: 0.0252549\ttotal: 5.04s\tremaining: 5.78s\n",
            "466:\tlearn: 0.0251850\ttotal: 5.05s\tremaining: 5.76s\n",
            "467:\tlearn: 0.0251170\ttotal: 5.05s\tremaining: 5.75s\n",
            "468:\tlearn: 0.0250329\ttotal: 5.06s\tremaining: 5.73s\n",
            "469:\tlearn: 0.0249457\ttotal: 5.07s\tremaining: 5.72s\n",
            "470:\tlearn: 0.0248506\ttotal: 5.08s\tremaining: 5.7s\n",
            "471:\tlearn: 0.0247595\ttotal: 5.08s\tremaining: 5.69s\n",
            "472:\tlearn: 0.0246816\ttotal: 5.09s\tremaining: 5.67s\n",
            "473:\tlearn: 0.0246097\ttotal: 5.1s\tremaining: 5.66s\n",
            "474:\tlearn: 0.0245550\ttotal: 5.11s\tremaining: 5.64s\n",
            "475:\tlearn: 0.0244352\ttotal: 5.11s\tremaining: 5.63s\n",
            "476:\tlearn: 0.0243300\ttotal: 5.12s\tremaining: 5.61s\n",
            "477:\tlearn: 0.0242548\ttotal: 5.13s\tremaining: 5.6s\n",
            "478:\tlearn: 0.0242034\ttotal: 5.14s\tremaining: 5.59s\n",
            "479:\tlearn: 0.0241267\ttotal: 5.14s\tremaining: 5.57s\n",
            "480:\tlearn: 0.0240505\ttotal: 5.15s\tremaining: 5.56s\n",
            "481:\tlearn: 0.0239549\ttotal: 5.16s\tremaining: 5.54s\n",
            "482:\tlearn: 0.0238517\ttotal: 5.17s\tremaining: 5.53s\n",
            "483:\tlearn: 0.0237844\ttotal: 5.17s\tremaining: 5.51s\n",
            "484:\tlearn: 0.0237147\ttotal: 5.18s\tremaining: 5.5s\n",
            "485:\tlearn: 0.0236270\ttotal: 5.19s\tremaining: 5.49s\n",
            "486:\tlearn: 0.0235736\ttotal: 5.2s\tremaining: 5.47s\n",
            "487:\tlearn: 0.0234885\ttotal: 5.2s\tremaining: 5.46s\n",
            "488:\tlearn: 0.0234125\ttotal: 5.21s\tremaining: 5.45s\n",
            "489:\tlearn: 0.0233353\ttotal: 5.22s\tremaining: 5.43s\n",
            "490:\tlearn: 0.0232778\ttotal: 5.23s\tremaining: 5.42s\n",
            "491:\tlearn: 0.0232107\ttotal: 5.24s\tremaining: 5.41s\n",
            "492:\tlearn: 0.0231396\ttotal: 5.25s\tremaining: 5.39s\n",
            "493:\tlearn: 0.0230619\ttotal: 5.25s\tremaining: 5.38s\n",
            "494:\tlearn: 0.0230004\ttotal: 5.26s\tremaining: 5.37s\n",
            "495:\tlearn: 0.0229267\ttotal: 5.27s\tremaining: 5.35s\n",
            "496:\tlearn: 0.0228717\ttotal: 5.27s\tremaining: 5.34s\n",
            "497:\tlearn: 0.0228068\ttotal: 5.28s\tremaining: 5.32s\n",
            "498:\tlearn: 0.0227362\ttotal: 5.29s\tremaining: 5.31s\n",
            "499:\tlearn: 0.0226920\ttotal: 5.3s\tremaining: 5.3s\n",
            "500:\tlearn: 0.0226189\ttotal: 5.3s\tremaining: 5.28s\n",
            "501:\tlearn: 0.0225853\ttotal: 5.31s\tremaining: 5.27s\n",
            "502:\tlearn: 0.0225266\ttotal: 5.32s\tremaining: 5.25s\n",
            "503:\tlearn: 0.0224557\ttotal: 5.33s\tremaining: 5.24s\n",
            "504:\tlearn: 0.0223951\ttotal: 5.33s\tremaining: 5.23s\n",
            "505:\tlearn: 0.0223413\ttotal: 5.34s\tremaining: 5.22s\n",
            "506:\tlearn: 0.0222662\ttotal: 5.35s\tremaining: 5.2s\n",
            "507:\tlearn: 0.0222022\ttotal: 5.36s\tremaining: 5.19s\n",
            "508:\tlearn: 0.0221383\ttotal: 5.37s\tremaining: 5.17s\n",
            "509:\tlearn: 0.0220810\ttotal: 5.37s\tremaining: 5.16s\n",
            "510:\tlearn: 0.0220081\ttotal: 5.38s\tremaining: 5.15s\n",
            "511:\tlearn: 0.0219580\ttotal: 5.39s\tremaining: 5.13s\n",
            "512:\tlearn: 0.0218536\ttotal: 5.39s\tremaining: 5.12s\n",
            "513:\tlearn: 0.0217978\ttotal: 5.4s\tremaining: 5.11s\n",
            "514:\tlearn: 0.0217314\ttotal: 5.41s\tremaining: 5.09s\n",
            "515:\tlearn: 0.0216689\ttotal: 5.42s\tremaining: 5.09s\n",
            "516:\tlearn: 0.0216028\ttotal: 5.43s\tremaining: 5.08s\n",
            "517:\tlearn: 0.0215178\ttotal: 5.45s\tremaining: 5.07s\n",
            "518:\tlearn: 0.0214814\ttotal: 5.46s\tremaining: 5.06s\n",
            "519:\tlearn: 0.0214595\ttotal: 5.47s\tremaining: 5.04s\n",
            "520:\tlearn: 0.0213973\ttotal: 5.47s\tremaining: 5.03s\n",
            "521:\tlearn: 0.0213365\ttotal: 5.48s\tremaining: 5.02s\n",
            "522:\tlearn: 0.0212647\ttotal: 5.49s\tremaining: 5.01s\n",
            "523:\tlearn: 0.0212370\ttotal: 5.5s\tremaining: 4.99s\n",
            "524:\tlearn: 0.0211662\ttotal: 5.5s\tremaining: 4.98s\n",
            "525:\tlearn: 0.0211254\ttotal: 5.51s\tremaining: 4.97s\n",
            "526:\tlearn: 0.0210915\ttotal: 5.52s\tremaining: 4.95s\n",
            "527:\tlearn: 0.0210251\ttotal: 5.53s\tremaining: 4.94s\n",
            "528:\tlearn: 0.0209587\ttotal: 5.54s\tremaining: 4.93s\n",
            "529:\tlearn: 0.0209119\ttotal: 5.54s\tremaining: 4.92s\n",
            "530:\tlearn: 0.0208553\ttotal: 5.55s\tremaining: 4.9s\n",
            "531:\tlearn: 0.0207913\ttotal: 5.56s\tremaining: 4.89s\n",
            "532:\tlearn: 0.0207405\ttotal: 5.57s\tremaining: 4.88s\n",
            "533:\tlearn: 0.0207004\ttotal: 5.58s\tremaining: 4.87s\n",
            "534:\tlearn: 0.0206400\ttotal: 5.58s\tremaining: 4.85s\n",
            "535:\tlearn: 0.0205671\ttotal: 5.59s\tremaining: 4.84s\n",
            "536:\tlearn: 0.0204906\ttotal: 5.6s\tremaining: 4.83s\n",
            "537:\tlearn: 0.0204346\ttotal: 5.61s\tremaining: 4.82s\n",
            "538:\tlearn: 0.0203811\ttotal: 5.62s\tremaining: 4.81s\n",
            "539:\tlearn: 0.0203286\ttotal: 5.63s\tremaining: 4.79s\n",
            "540:\tlearn: 0.0202828\ttotal: 5.64s\tremaining: 4.78s\n",
            "541:\tlearn: 0.0202232\ttotal: 5.64s\tremaining: 4.77s\n",
            "542:\tlearn: 0.0201816\ttotal: 5.65s\tremaining: 4.76s\n",
            "543:\tlearn: 0.0201146\ttotal: 5.66s\tremaining: 4.74s\n",
            "544:\tlearn: 0.0200472\ttotal: 5.67s\tremaining: 4.73s\n",
            "545:\tlearn: 0.0200160\ttotal: 5.67s\tremaining: 4.72s\n",
            "546:\tlearn: 0.0199558\ttotal: 5.68s\tremaining: 4.71s\n",
            "547:\tlearn: 0.0199144\ttotal: 5.69s\tremaining: 4.69s\n",
            "548:\tlearn: 0.0198696\ttotal: 5.7s\tremaining: 4.68s\n",
            "549:\tlearn: 0.0198243\ttotal: 5.71s\tremaining: 4.67s\n",
            "550:\tlearn: 0.0197689\ttotal: 5.71s\tremaining: 4.66s\n",
            "551:\tlearn: 0.0197455\ttotal: 5.72s\tremaining: 4.64s\n",
            "552:\tlearn: 0.0197123\ttotal: 5.73s\tremaining: 4.63s\n",
            "553:\tlearn: 0.0196538\ttotal: 5.74s\tremaining: 4.62s\n",
            "554:\tlearn: 0.0195897\ttotal: 5.74s\tremaining: 4.61s\n",
            "555:\tlearn: 0.0195515\ttotal: 5.75s\tremaining: 4.59s\n",
            "556:\tlearn: 0.0195232\ttotal: 5.76s\tremaining: 4.58s\n",
            "557:\tlearn: 0.0194741\ttotal: 5.77s\tremaining: 4.57s\n",
            "558:\tlearn: 0.0194526\ttotal: 5.77s\tremaining: 4.55s\n",
            "559:\tlearn: 0.0193928\ttotal: 5.78s\tremaining: 4.54s\n",
            "560:\tlearn: 0.0193493\ttotal: 5.79s\tremaining: 4.53s\n",
            "561:\tlearn: 0.0193003\ttotal: 5.8s\tremaining: 4.52s\n",
            "562:\tlearn: 0.0192684\ttotal: 5.8s\tremaining: 4.51s\n",
            "563:\tlearn: 0.0191992\ttotal: 5.81s\tremaining: 4.49s\n",
            "564:\tlearn: 0.0191647\ttotal: 5.82s\tremaining: 4.48s\n",
            "565:\tlearn: 0.0191077\ttotal: 5.83s\tremaining: 4.47s\n",
            "566:\tlearn: 0.0190461\ttotal: 5.84s\tremaining: 4.46s\n",
            "567:\tlearn: 0.0190018\ttotal: 5.84s\tremaining: 4.45s\n",
            "568:\tlearn: 0.0189528\ttotal: 5.85s\tremaining: 4.43s\n",
            "569:\tlearn: 0.0188910\ttotal: 5.86s\tremaining: 4.42s\n",
            "570:\tlearn: 0.0188494\ttotal: 5.87s\tremaining: 4.41s\n",
            "571:\tlearn: 0.0188063\ttotal: 5.87s\tremaining: 4.39s\n",
            "572:\tlearn: 0.0187482\ttotal: 5.88s\tremaining: 4.38s\n",
            "573:\tlearn: 0.0186977\ttotal: 5.89s\tremaining: 4.37s\n",
            "574:\tlearn: 0.0186398\ttotal: 5.9s\tremaining: 4.36s\n",
            "575:\tlearn: 0.0186093\ttotal: 5.9s\tremaining: 4.34s\n",
            "576:\tlearn: 0.0185557\ttotal: 5.91s\tremaining: 4.33s\n",
            "577:\tlearn: 0.0185114\ttotal: 5.92s\tremaining: 4.32s\n",
            "578:\tlearn: 0.0184921\ttotal: 5.93s\tremaining: 4.31s\n",
            "579:\tlearn: 0.0184442\ttotal: 5.93s\tremaining: 4.3s\n",
            "580:\tlearn: 0.0184016\ttotal: 5.94s\tremaining: 4.29s\n",
            "581:\tlearn: 0.0183711\ttotal: 5.95s\tremaining: 4.27s\n",
            "582:\tlearn: 0.0183404\ttotal: 5.96s\tremaining: 4.26s\n",
            "583:\tlearn: 0.0182983\ttotal: 5.97s\tremaining: 4.25s\n",
            "584:\tlearn: 0.0182528\ttotal: 5.97s\tremaining: 4.24s\n",
            "585:\tlearn: 0.0182121\ttotal: 5.98s\tremaining: 4.23s\n",
            "586:\tlearn: 0.0181642\ttotal: 5.99s\tremaining: 4.21s\n",
            "587:\tlearn: 0.0181339\ttotal: 6s\tremaining: 4.2s\n",
            "588:\tlearn: 0.0180973\ttotal: 6s\tremaining: 4.19s\n",
            "589:\tlearn: 0.0180589\ttotal: 6.01s\tremaining: 4.18s\n",
            "590:\tlearn: 0.0180147\ttotal: 6.02s\tremaining: 4.17s\n",
            "591:\tlearn: 0.0179704\ttotal: 6.03s\tremaining: 4.15s\n",
            "592:\tlearn: 0.0179328\ttotal: 6.03s\tremaining: 4.14s\n",
            "593:\tlearn: 0.0178931\ttotal: 6.04s\tremaining: 4.13s\n",
            "594:\tlearn: 0.0178401\ttotal: 6.05s\tremaining: 4.12s\n",
            "595:\tlearn: 0.0177844\ttotal: 6.06s\tremaining: 4.11s\n",
            "596:\tlearn: 0.0177412\ttotal: 6.06s\tremaining: 4.09s\n",
            "597:\tlearn: 0.0176937\ttotal: 6.07s\tremaining: 4.08s\n",
            "598:\tlearn: 0.0176446\ttotal: 6.08s\tremaining: 4.07s\n",
            "599:\tlearn: 0.0175951\ttotal: 6.08s\tremaining: 4.06s\n",
            "600:\tlearn: 0.0175558\ttotal: 6.09s\tremaining: 4.04s\n",
            "601:\tlearn: 0.0175320\ttotal: 6.1s\tremaining: 4.03s\n",
            "602:\tlearn: 0.0174848\ttotal: 6.11s\tremaining: 4.02s\n",
            "603:\tlearn: 0.0174238\ttotal: 6.12s\tremaining: 4.01s\n",
            "604:\tlearn: 0.0173791\ttotal: 6.12s\tremaining: 4s\n",
            "605:\tlearn: 0.0173335\ttotal: 6.13s\tremaining: 3.98s\n",
            "606:\tlearn: 0.0172872\ttotal: 6.14s\tremaining: 3.98s\n",
            "607:\tlearn: 0.0172355\ttotal: 6.15s\tremaining: 3.96s\n",
            "608:\tlearn: 0.0172087\ttotal: 6.16s\tremaining: 3.95s\n",
            "609:\tlearn: 0.0171765\ttotal: 6.16s\tremaining: 3.94s\n",
            "610:\tlearn: 0.0171203\ttotal: 6.17s\tremaining: 3.93s\n",
            "611:\tlearn: 0.0170528\ttotal: 6.18s\tremaining: 3.92s\n",
            "612:\tlearn: 0.0169978\ttotal: 6.19s\tremaining: 3.9s\n",
            "613:\tlearn: 0.0169643\ttotal: 6.19s\tremaining: 3.89s\n",
            "614:\tlearn: 0.0169065\ttotal: 6.2s\tremaining: 3.88s\n",
            "615:\tlearn: 0.0168730\ttotal: 6.21s\tremaining: 3.87s\n",
            "616:\tlearn: 0.0168378\ttotal: 6.21s\tremaining: 3.86s\n",
            "617:\tlearn: 0.0167979\ttotal: 6.22s\tremaining: 3.85s\n",
            "618:\tlearn: 0.0167691\ttotal: 6.23s\tremaining: 3.83s\n",
            "619:\tlearn: 0.0167330\ttotal: 6.24s\tremaining: 3.82s\n",
            "620:\tlearn: 0.0167052\ttotal: 6.24s\tremaining: 3.81s\n",
            "621:\tlearn: 0.0166609\ttotal: 6.25s\tremaining: 3.8s\n",
            "622:\tlearn: 0.0166352\ttotal: 6.26s\tremaining: 3.79s\n",
            "623:\tlearn: 0.0166011\ttotal: 6.27s\tremaining: 3.78s\n",
            "624:\tlearn: 0.0165649\ttotal: 6.28s\tremaining: 3.77s\n",
            "625:\tlearn: 0.0165434\ttotal: 6.28s\tremaining: 3.75s\n",
            "626:\tlearn: 0.0165056\ttotal: 6.29s\tremaining: 3.74s\n",
            "627:\tlearn: 0.0164528\ttotal: 6.3s\tremaining: 3.73s\n",
            "628:\tlearn: 0.0164081\ttotal: 6.3s\tremaining: 3.72s\n",
            "629:\tlearn: 0.0163765\ttotal: 6.31s\tremaining: 3.71s\n",
            "630:\tlearn: 0.0163273\ttotal: 6.32s\tremaining: 3.69s\n",
            "631:\tlearn: 0.0163007\ttotal: 6.33s\tremaining: 3.68s\n",
            "632:\tlearn: 0.0162513\ttotal: 6.33s\tremaining: 3.67s\n",
            "633:\tlearn: 0.0162209\ttotal: 6.34s\tremaining: 3.66s\n",
            "634:\tlearn: 0.0161958\ttotal: 6.35s\tremaining: 3.65s\n",
            "635:\tlearn: 0.0161444\ttotal: 6.36s\tremaining: 3.64s\n",
            "636:\tlearn: 0.0161154\ttotal: 6.37s\tremaining: 3.63s\n",
            "637:\tlearn: 0.0160797\ttotal: 6.37s\tremaining: 3.62s\n",
            "638:\tlearn: 0.0160253\ttotal: 6.38s\tremaining: 3.6s\n",
            "639:\tlearn: 0.0159896\ttotal: 6.39s\tremaining: 3.59s\n",
            "640:\tlearn: 0.0159623\ttotal: 6.39s\tremaining: 3.58s\n",
            "641:\tlearn: 0.0159343\ttotal: 6.4s\tremaining: 3.57s\n",
            "642:\tlearn: 0.0159051\ttotal: 6.41s\tremaining: 3.56s\n",
            "643:\tlearn: 0.0158536\ttotal: 6.42s\tremaining: 3.55s\n",
            "644:\tlearn: 0.0158101\ttotal: 6.42s\tremaining: 3.54s\n",
            "645:\tlearn: 0.0157816\ttotal: 6.43s\tremaining: 3.53s\n",
            "646:\tlearn: 0.0157527\ttotal: 6.44s\tremaining: 3.52s\n",
            "647:\tlearn: 0.0157116\ttotal: 6.45s\tremaining: 3.5s\n",
            "648:\tlearn: 0.0156819\ttotal: 6.47s\tremaining: 3.5s\n",
            "649:\tlearn: 0.0156670\ttotal: 6.48s\tremaining: 3.49s\n",
            "650:\tlearn: 0.0156234\ttotal: 6.49s\tremaining: 3.48s\n",
            "651:\tlearn: 0.0155785\ttotal: 6.5s\tremaining: 3.47s\n",
            "652:\tlearn: 0.0155690\ttotal: 6.5s\tremaining: 3.46s\n",
            "653:\tlearn: 0.0155412\ttotal: 6.51s\tremaining: 3.44s\n",
            "654:\tlearn: 0.0155004\ttotal: 6.52s\tremaining: 3.43s\n",
            "655:\tlearn: 0.0154880\ttotal: 6.52s\tremaining: 3.42s\n",
            "656:\tlearn: 0.0154502\ttotal: 6.53s\tremaining: 3.41s\n",
            "657:\tlearn: 0.0154184\ttotal: 6.54s\tremaining: 3.4s\n",
            "658:\tlearn: 0.0153706\ttotal: 6.55s\tremaining: 3.39s\n",
            "659:\tlearn: 0.0153343\ttotal: 6.56s\tremaining: 3.38s\n",
            "660:\tlearn: 0.0153042\ttotal: 6.56s\tremaining: 3.37s\n",
            "661:\tlearn: 0.0152732\ttotal: 6.57s\tremaining: 3.35s\n",
            "662:\tlearn: 0.0152426\ttotal: 6.58s\tremaining: 3.34s\n",
            "663:\tlearn: 0.0152188\ttotal: 6.58s\tremaining: 3.33s\n",
            "664:\tlearn: 0.0151756\ttotal: 6.59s\tremaining: 3.32s\n",
            "665:\tlearn: 0.0151359\ttotal: 6.6s\tremaining: 3.31s\n",
            "666:\tlearn: 0.0150997\ttotal: 6.61s\tremaining: 3.3s\n",
            "667:\tlearn: 0.0150594\ttotal: 6.62s\tremaining: 3.29s\n",
            "668:\tlearn: 0.0150242\ttotal: 6.62s\tremaining: 3.28s\n",
            "669:\tlearn: 0.0149972\ttotal: 6.63s\tremaining: 3.27s\n",
            "670:\tlearn: 0.0149519\ttotal: 6.64s\tremaining: 3.25s\n",
            "671:\tlearn: 0.0149208\ttotal: 6.65s\tremaining: 3.24s\n",
            "672:\tlearn: 0.0148985\ttotal: 6.65s\tremaining: 3.23s\n",
            "673:\tlearn: 0.0148733\ttotal: 6.66s\tremaining: 3.22s\n",
            "674:\tlearn: 0.0148362\ttotal: 6.67s\tremaining: 3.21s\n",
            "675:\tlearn: 0.0147928\ttotal: 6.67s\tremaining: 3.2s\n",
            "676:\tlearn: 0.0147642\ttotal: 6.68s\tremaining: 3.19s\n",
            "677:\tlearn: 0.0147525\ttotal: 6.69s\tremaining: 3.18s\n",
            "678:\tlearn: 0.0147246\ttotal: 6.7s\tremaining: 3.17s\n",
            "679:\tlearn: 0.0146959\ttotal: 6.71s\tremaining: 3.15s\n",
            "680:\tlearn: 0.0146617\ttotal: 6.71s\tremaining: 3.14s\n",
            "681:\tlearn: 0.0146330\ttotal: 6.72s\tremaining: 3.13s\n",
            "682:\tlearn: 0.0145962\ttotal: 6.73s\tremaining: 3.12s\n",
            "683:\tlearn: 0.0145490\ttotal: 6.73s\tremaining: 3.11s\n",
            "684:\tlearn: 0.0145209\ttotal: 6.74s\tremaining: 3.1s\n",
            "685:\tlearn: 0.0144996\ttotal: 6.75s\tremaining: 3.09s\n",
            "686:\tlearn: 0.0144748\ttotal: 6.76s\tremaining: 3.08s\n",
            "687:\tlearn: 0.0144378\ttotal: 6.77s\tremaining: 3.07s\n",
            "688:\tlearn: 0.0144123\ttotal: 6.78s\tremaining: 3.06s\n",
            "689:\tlearn: 0.0143845\ttotal: 6.78s\tremaining: 3.05s\n",
            "690:\tlearn: 0.0143476\ttotal: 6.79s\tremaining: 3.04s\n",
            "691:\tlearn: 0.0143225\ttotal: 6.8s\tremaining: 3.03s\n",
            "692:\tlearn: 0.0142871\ttotal: 6.8s\tremaining: 3.02s\n",
            "693:\tlearn: 0.0142519\ttotal: 6.81s\tremaining: 3s\n",
            "694:\tlearn: 0.0142208\ttotal: 6.82s\tremaining: 2.99s\n",
            "695:\tlearn: 0.0142122\ttotal: 6.83s\tremaining: 2.98s\n",
            "696:\tlearn: 0.0141733\ttotal: 6.83s\tremaining: 2.97s\n",
            "697:\tlearn: 0.0141383\ttotal: 6.84s\tremaining: 2.96s\n",
            "698:\tlearn: 0.0141052\ttotal: 6.85s\tremaining: 2.95s\n",
            "699:\tlearn: 0.0140916\ttotal: 6.86s\tremaining: 2.94s\n",
            "700:\tlearn: 0.0140715\ttotal: 6.86s\tremaining: 2.93s\n",
            "701:\tlearn: 0.0140570\ttotal: 6.87s\tremaining: 2.92s\n",
            "702:\tlearn: 0.0140253\ttotal: 6.88s\tremaining: 2.9s\n",
            "703:\tlearn: 0.0140030\ttotal: 6.88s\tremaining: 2.9s\n",
            "704:\tlearn: 0.0139790\ttotal: 6.89s\tremaining: 2.88s\n",
            "705:\tlearn: 0.0139644\ttotal: 6.9s\tremaining: 2.87s\n",
            "706:\tlearn: 0.0139306\ttotal: 6.91s\tremaining: 2.86s\n",
            "707:\tlearn: 0.0139076\ttotal: 6.91s\tremaining: 2.85s\n",
            "708:\tlearn: 0.0138761\ttotal: 6.92s\tremaining: 2.84s\n",
            "709:\tlearn: 0.0138544\ttotal: 6.93s\tremaining: 2.83s\n",
            "710:\tlearn: 0.0138230\ttotal: 6.93s\tremaining: 2.82s\n",
            "711:\tlearn: 0.0137897\ttotal: 6.94s\tremaining: 2.81s\n",
            "712:\tlearn: 0.0137552\ttotal: 6.95s\tremaining: 2.8s\n",
            "713:\tlearn: 0.0137525\ttotal: 6.96s\tremaining: 2.79s\n",
            "714:\tlearn: 0.0137194\ttotal: 6.97s\tremaining: 2.78s\n",
            "715:\tlearn: 0.0137122\ttotal: 6.97s\tremaining: 2.77s\n",
            "716:\tlearn: 0.0136965\ttotal: 6.98s\tremaining: 2.75s\n",
            "717:\tlearn: 0.0136875\ttotal: 6.99s\tremaining: 2.75s\n",
            "718:\tlearn: 0.0136690\ttotal: 7s\tremaining: 2.73s\n",
            "719:\tlearn: 0.0136316\ttotal: 7s\tremaining: 2.72s\n",
            "720:\tlearn: 0.0136010\ttotal: 7.01s\tremaining: 2.71s\n",
            "721:\tlearn: 0.0135730\ttotal: 7.02s\tremaining: 2.7s\n",
            "722:\tlearn: 0.0135381\ttotal: 7.03s\tremaining: 2.69s\n",
            "723:\tlearn: 0.0135131\ttotal: 7.03s\tremaining: 2.68s\n",
            "724:\tlearn: 0.0134844\ttotal: 7.04s\tremaining: 2.67s\n",
            "725:\tlearn: 0.0134534\ttotal: 7.05s\tremaining: 2.66s\n",
            "726:\tlearn: 0.0134265\ttotal: 7.06s\tremaining: 2.65s\n",
            "727:\tlearn: 0.0134039\ttotal: 7.06s\tremaining: 2.64s\n",
            "728:\tlearn: 0.0133880\ttotal: 7.07s\tremaining: 2.63s\n",
            "729:\tlearn: 0.0133606\ttotal: 7.08s\tremaining: 2.62s\n",
            "730:\tlearn: 0.0133327\ttotal: 7.09s\tremaining: 2.61s\n",
            "731:\tlearn: 0.0132992\ttotal: 7.09s\tremaining: 2.6s\n",
            "732:\tlearn: 0.0132713\ttotal: 7.1s\tremaining: 2.59s\n",
            "733:\tlearn: 0.0132313\ttotal: 7.11s\tremaining: 2.58s\n",
            "734:\tlearn: 0.0131999\ttotal: 7.12s\tremaining: 2.56s\n",
            "735:\tlearn: 0.0131659\ttotal: 7.12s\tremaining: 2.55s\n",
            "736:\tlearn: 0.0131557\ttotal: 7.13s\tremaining: 2.54s\n",
            "737:\tlearn: 0.0131246\ttotal: 7.14s\tremaining: 2.53s\n",
            "738:\tlearn: 0.0131060\ttotal: 7.14s\tremaining: 2.52s\n",
            "739:\tlearn: 0.0130840\ttotal: 7.16s\tremaining: 2.51s\n",
            "740:\tlearn: 0.0130674\ttotal: 7.16s\tremaining: 2.5s\n",
            "741:\tlearn: 0.0130549\ttotal: 7.17s\tremaining: 2.49s\n",
            "742:\tlearn: 0.0130370\ttotal: 7.18s\tremaining: 2.48s\n",
            "743:\tlearn: 0.0130193\ttotal: 7.18s\tremaining: 2.47s\n",
            "744:\tlearn: 0.0129846\ttotal: 7.19s\tremaining: 2.46s\n",
            "745:\tlearn: 0.0129537\ttotal: 7.2s\tremaining: 2.45s\n",
            "746:\tlearn: 0.0129245\ttotal: 7.21s\tremaining: 2.44s\n",
            "747:\tlearn: 0.0128991\ttotal: 7.21s\tremaining: 2.43s\n",
            "748:\tlearn: 0.0128655\ttotal: 7.22s\tremaining: 2.42s\n",
            "749:\tlearn: 0.0128501\ttotal: 7.23s\tremaining: 2.41s\n",
            "750:\tlearn: 0.0128187\ttotal: 7.24s\tremaining: 2.4s\n",
            "751:\tlearn: 0.0127993\ttotal: 7.24s\tremaining: 2.39s\n",
            "752:\tlearn: 0.0127632\ttotal: 7.25s\tremaining: 2.38s\n",
            "753:\tlearn: 0.0127417\ttotal: 7.26s\tremaining: 2.37s\n",
            "754:\tlearn: 0.0127253\ttotal: 7.26s\tremaining: 2.36s\n",
            "755:\tlearn: 0.0127061\ttotal: 7.27s\tremaining: 2.35s\n",
            "756:\tlearn: 0.0126823\ttotal: 7.28s\tremaining: 2.34s\n",
            "757:\tlearn: 0.0126684\ttotal: 7.29s\tremaining: 2.33s\n",
            "758:\tlearn: 0.0126433\ttotal: 7.29s\tremaining: 2.31s\n",
            "759:\tlearn: 0.0126158\ttotal: 7.3s\tremaining: 2.31s\n",
            "760:\tlearn: 0.0125801\ttotal: 7.31s\tremaining: 2.29s\n",
            "761:\tlearn: 0.0125787\ttotal: 7.32s\tremaining: 2.28s\n",
            "762:\tlearn: 0.0125495\ttotal: 7.32s\tremaining: 2.27s\n",
            "763:\tlearn: 0.0125288\ttotal: 7.33s\tremaining: 2.26s\n",
            "764:\tlearn: 0.0125054\ttotal: 7.34s\tremaining: 2.25s\n",
            "765:\tlearn: 0.0124852\ttotal: 7.34s\tremaining: 2.24s\n",
            "766:\tlearn: 0.0124560\ttotal: 7.35s\tremaining: 2.23s\n",
            "767:\tlearn: 0.0124340\ttotal: 7.36s\tremaining: 2.22s\n",
            "768:\tlearn: 0.0124078\ttotal: 7.37s\tremaining: 2.21s\n",
            "769:\tlearn: 0.0123822\ttotal: 7.38s\tremaining: 2.2s\n",
            "770:\tlearn: 0.0123491\ttotal: 7.38s\tremaining: 2.19s\n",
            "771:\tlearn: 0.0123415\ttotal: 7.39s\tremaining: 2.18s\n",
            "772:\tlearn: 0.0123187\ttotal: 7.4s\tremaining: 2.17s\n",
            "773:\tlearn: 0.0123031\ttotal: 7.41s\tremaining: 2.16s\n",
            "774:\tlearn: 0.0122811\ttotal: 7.41s\tremaining: 2.15s\n",
            "775:\tlearn: 0.0122625\ttotal: 7.42s\tremaining: 2.14s\n",
            "776:\tlearn: 0.0122305\ttotal: 7.43s\tremaining: 2.13s\n",
            "777:\tlearn: 0.0122064\ttotal: 7.43s\tremaining: 2.12s\n",
            "778:\tlearn: 0.0121709\ttotal: 7.44s\tremaining: 2.11s\n",
            "779:\tlearn: 0.0121531\ttotal: 7.45s\tremaining: 2.1s\n",
            "780:\tlearn: 0.0121265\ttotal: 7.46s\tremaining: 2.09s\n",
            "781:\tlearn: 0.0121116\ttotal: 7.47s\tremaining: 2.08s\n",
            "782:\tlearn: 0.0120920\ttotal: 7.48s\tremaining: 2.07s\n",
            "783:\tlearn: 0.0120694\ttotal: 7.49s\tremaining: 2.06s\n",
            "784:\tlearn: 0.0120489\ttotal: 7.51s\tremaining: 2.06s\n",
            "785:\tlearn: 0.0120217\ttotal: 7.51s\tremaining: 2.05s\n",
            "786:\tlearn: 0.0119986\ttotal: 7.52s\tremaining: 2.04s\n",
            "787:\tlearn: 0.0119709\ttotal: 7.53s\tremaining: 2.03s\n",
            "788:\tlearn: 0.0119538\ttotal: 7.54s\tremaining: 2.02s\n",
            "789:\tlearn: 0.0119273\ttotal: 7.55s\tremaining: 2.01s\n",
            "790:\tlearn: 0.0118954\ttotal: 7.55s\tremaining: 2s\n",
            "791:\tlearn: 0.0118838\ttotal: 7.56s\tremaining: 1.99s\n",
            "792:\tlearn: 0.0118500\ttotal: 7.57s\tremaining: 1.98s\n",
            "793:\tlearn: 0.0118237\ttotal: 7.58s\tremaining: 1.97s\n",
            "794:\tlearn: 0.0118077\ttotal: 7.59s\tremaining: 1.96s\n",
            "795:\tlearn: 0.0117740\ttotal: 7.59s\tremaining: 1.95s\n",
            "796:\tlearn: 0.0117529\ttotal: 7.6s\tremaining: 1.94s\n",
            "797:\tlearn: 0.0117295\ttotal: 7.61s\tremaining: 1.93s\n",
            "798:\tlearn: 0.0117033\ttotal: 7.62s\tremaining: 1.92s\n",
            "799:\tlearn: 0.0116785\ttotal: 7.63s\tremaining: 1.91s\n",
            "800:\tlearn: 0.0116514\ttotal: 7.63s\tremaining: 1.9s\n",
            "801:\tlearn: 0.0116174\ttotal: 7.64s\tremaining: 1.89s\n",
            "802:\tlearn: 0.0115977\ttotal: 7.65s\tremaining: 1.88s\n",
            "803:\tlearn: 0.0115741\ttotal: 7.66s\tremaining: 1.87s\n",
            "804:\tlearn: 0.0115522\ttotal: 7.66s\tremaining: 1.86s\n",
            "805:\tlearn: 0.0115287\ttotal: 7.67s\tremaining: 1.85s\n",
            "806:\tlearn: 0.0115116\ttotal: 7.68s\tremaining: 1.84s\n",
            "807:\tlearn: 0.0114983\ttotal: 7.69s\tremaining: 1.83s\n",
            "808:\tlearn: 0.0114816\ttotal: 7.69s\tremaining: 1.82s\n",
            "809:\tlearn: 0.0114542\ttotal: 7.7s\tremaining: 1.81s\n",
            "810:\tlearn: 0.0114383\ttotal: 7.71s\tremaining: 1.8s\n",
            "811:\tlearn: 0.0114270\ttotal: 7.72s\tremaining: 1.79s\n",
            "812:\tlearn: 0.0113941\ttotal: 7.72s\tremaining: 1.78s\n",
            "813:\tlearn: 0.0113785\ttotal: 7.73s\tremaining: 1.77s\n",
            "814:\tlearn: 0.0113681\ttotal: 7.74s\tremaining: 1.76s\n",
            "815:\tlearn: 0.0113384\ttotal: 7.75s\tremaining: 1.75s\n",
            "816:\tlearn: 0.0113331\ttotal: 7.75s\tremaining: 1.74s\n",
            "817:\tlearn: 0.0113146\ttotal: 7.76s\tremaining: 1.73s\n",
            "818:\tlearn: 0.0112928\ttotal: 7.77s\tremaining: 1.72s\n",
            "819:\tlearn: 0.0112709\ttotal: 7.78s\tremaining: 1.71s\n",
            "820:\tlearn: 0.0112495\ttotal: 7.79s\tremaining: 1.7s\n",
            "821:\tlearn: 0.0112271\ttotal: 7.79s\tremaining: 1.69s\n",
            "822:\tlearn: 0.0112093\ttotal: 7.8s\tremaining: 1.68s\n",
            "823:\tlearn: 0.0111810\ttotal: 7.81s\tremaining: 1.67s\n",
            "824:\tlearn: 0.0111529\ttotal: 7.81s\tremaining: 1.66s\n",
            "825:\tlearn: 0.0111295\ttotal: 7.82s\tremaining: 1.65s\n",
            "826:\tlearn: 0.0111125\ttotal: 7.83s\tremaining: 1.64s\n",
            "827:\tlearn: 0.0110851\ttotal: 7.84s\tremaining: 1.63s\n",
            "828:\tlearn: 0.0110591\ttotal: 7.84s\tremaining: 1.62s\n",
            "829:\tlearn: 0.0110330\ttotal: 7.85s\tremaining: 1.61s\n",
            "830:\tlearn: 0.0110202\ttotal: 7.86s\tremaining: 1.6s\n",
            "831:\tlearn: 0.0110026\ttotal: 7.87s\tremaining: 1.59s\n",
            "832:\tlearn: 0.0109718\ttotal: 7.87s\tremaining: 1.58s\n",
            "833:\tlearn: 0.0109506\ttotal: 7.88s\tremaining: 1.57s\n",
            "834:\tlearn: 0.0109336\ttotal: 7.89s\tremaining: 1.56s\n",
            "835:\tlearn: 0.0109117\ttotal: 7.89s\tremaining: 1.55s\n",
            "836:\tlearn: 0.0108878\ttotal: 7.9s\tremaining: 1.54s\n",
            "837:\tlearn: 0.0108651\ttotal: 7.91s\tremaining: 1.53s\n",
            "838:\tlearn: 0.0108526\ttotal: 7.92s\tremaining: 1.52s\n",
            "839:\tlearn: 0.0108481\ttotal: 7.92s\tremaining: 1.51s\n",
            "840:\tlearn: 0.0108346\ttotal: 7.93s\tremaining: 1.5s\n",
            "841:\tlearn: 0.0108056\ttotal: 7.94s\tremaining: 1.49s\n",
            "842:\tlearn: 0.0107774\ttotal: 7.95s\tremaining: 1.48s\n",
            "843:\tlearn: 0.0107691\ttotal: 7.95s\tremaining: 1.47s\n",
            "844:\tlearn: 0.0107434\ttotal: 7.96s\tremaining: 1.46s\n",
            "845:\tlearn: 0.0107174\ttotal: 7.97s\tremaining: 1.45s\n",
            "846:\tlearn: 0.0107157\ttotal: 7.98s\tremaining: 1.44s\n",
            "847:\tlearn: 0.0106877\ttotal: 7.99s\tremaining: 1.43s\n",
            "848:\tlearn: 0.0106569\ttotal: 8s\tremaining: 1.42s\n",
            "849:\tlearn: 0.0106375\ttotal: 8s\tremaining: 1.41s\n",
            "850:\tlearn: 0.0106180\ttotal: 8.01s\tremaining: 1.4s\n",
            "851:\tlearn: 0.0105952\ttotal: 8.02s\tremaining: 1.39s\n",
            "852:\tlearn: 0.0105937\ttotal: 8.02s\tremaining: 1.38s\n",
            "853:\tlearn: 0.0105738\ttotal: 8.03s\tremaining: 1.37s\n",
            "854:\tlearn: 0.0105523\ttotal: 8.04s\tremaining: 1.36s\n",
            "855:\tlearn: 0.0105340\ttotal: 8.05s\tremaining: 1.35s\n",
            "856:\tlearn: 0.0105166\ttotal: 8.05s\tremaining: 1.34s\n",
            "857:\tlearn: 0.0105070\ttotal: 8.06s\tremaining: 1.33s\n",
            "858:\tlearn: 0.0104846\ttotal: 8.07s\tremaining: 1.32s\n",
            "859:\tlearn: 0.0104742\ttotal: 8.08s\tremaining: 1.31s\n",
            "860:\tlearn: 0.0104454\ttotal: 8.08s\tremaining: 1.3s\n",
            "861:\tlearn: 0.0104248\ttotal: 8.09s\tremaining: 1.29s\n",
            "862:\tlearn: 0.0104089\ttotal: 8.1s\tremaining: 1.28s\n",
            "863:\tlearn: 0.0103763\ttotal: 8.11s\tremaining: 1.27s\n",
            "864:\tlearn: 0.0103577\ttotal: 8.11s\tremaining: 1.27s\n",
            "865:\tlearn: 0.0103335\ttotal: 8.12s\tremaining: 1.26s\n",
            "866:\tlearn: 0.0103071\ttotal: 8.13s\tremaining: 1.25s\n",
            "867:\tlearn: 0.0102839\ttotal: 8.13s\tremaining: 1.24s\n",
            "868:\tlearn: 0.0102633\ttotal: 8.14s\tremaining: 1.23s\n",
            "869:\tlearn: 0.0102457\ttotal: 8.15s\tremaining: 1.22s\n",
            "870:\tlearn: 0.0102233\ttotal: 8.16s\tremaining: 1.21s\n",
            "871:\tlearn: 0.0102023\ttotal: 8.17s\tremaining: 1.2s\n",
            "872:\tlearn: 0.0101857\ttotal: 8.18s\tremaining: 1.19s\n",
            "873:\tlearn: 0.0101658\ttotal: 8.18s\tremaining: 1.18s\n",
            "874:\tlearn: 0.0101466\ttotal: 8.19s\tremaining: 1.17s\n",
            "875:\tlearn: 0.0101154\ttotal: 8.2s\tremaining: 1.16s\n",
            "876:\tlearn: 0.0100951\ttotal: 8.21s\tremaining: 1.15s\n",
            "877:\tlearn: 0.0100792\ttotal: 8.21s\tremaining: 1.14s\n",
            "878:\tlearn: 0.0100770\ttotal: 8.22s\tremaining: 1.13s\n",
            "879:\tlearn: 0.0100600\ttotal: 8.23s\tremaining: 1.12s\n",
            "880:\tlearn: 0.0100383\ttotal: 8.23s\tremaining: 1.11s\n",
            "881:\tlearn: 0.0100199\ttotal: 8.24s\tremaining: 1.1s\n",
            "882:\tlearn: 0.0099962\ttotal: 8.25s\tremaining: 1.09s\n",
            "883:\tlearn: 0.0099759\ttotal: 8.26s\tremaining: 1.08s\n",
            "884:\tlearn: 0.0099549\ttotal: 8.27s\tremaining: 1.07s\n",
            "885:\tlearn: 0.0099315\ttotal: 8.27s\tremaining: 1.06s\n",
            "886:\tlearn: 0.0099085\ttotal: 8.28s\tremaining: 1.05s\n",
            "887:\tlearn: 0.0098913\ttotal: 8.29s\tremaining: 1.04s\n",
            "888:\tlearn: 0.0098815\ttotal: 8.3s\tremaining: 1.03s\n",
            "889:\tlearn: 0.0098598\ttotal: 8.3s\tremaining: 1.03s\n",
            "890:\tlearn: 0.0098473\ttotal: 8.31s\tremaining: 1.02s\n",
            "891:\tlearn: 0.0098438\ttotal: 8.32s\tremaining: 1.01s\n",
            "892:\tlearn: 0.0098248\ttotal: 8.33s\tremaining: 998ms\n",
            "893:\tlearn: 0.0098049\ttotal: 8.33s\tremaining: 988ms\n",
            "894:\tlearn: 0.0098041\ttotal: 8.34s\tremaining: 979ms\n",
            "895:\tlearn: 0.0097803\ttotal: 8.35s\tremaining: 969ms\n",
            "896:\tlearn: 0.0097637\ttotal: 8.36s\tremaining: 959ms\n",
            "897:\tlearn: 0.0097548\ttotal: 8.36s\tremaining: 950ms\n",
            "898:\tlearn: 0.0097535\ttotal: 8.37s\tremaining: 941ms\n",
            "899:\tlearn: 0.0097393\ttotal: 8.38s\tremaining: 931ms\n",
            "900:\tlearn: 0.0097233\ttotal: 8.39s\tremaining: 922ms\n",
            "901:\tlearn: 0.0097136\ttotal: 8.39s\tremaining: 912ms\n",
            "902:\tlearn: 0.0096910\ttotal: 8.4s\tremaining: 903ms\n",
            "903:\tlearn: 0.0096663\ttotal: 8.41s\tremaining: 893ms\n",
            "904:\tlearn: 0.0096491\ttotal: 8.42s\tremaining: 884ms\n",
            "905:\tlearn: 0.0096321\ttotal: 8.43s\tremaining: 874ms\n",
            "906:\tlearn: 0.0096161\ttotal: 8.43s\tremaining: 865ms\n",
            "907:\tlearn: 0.0095985\ttotal: 8.44s\tremaining: 855ms\n",
            "908:\tlearn: 0.0095800\ttotal: 8.45s\tremaining: 846ms\n",
            "909:\tlearn: 0.0095620\ttotal: 8.46s\tremaining: 836ms\n",
            "910:\tlearn: 0.0095382\ttotal: 8.46s\tremaining: 827ms\n",
            "911:\tlearn: 0.0095347\ttotal: 8.47s\tremaining: 817ms\n",
            "912:\tlearn: 0.0095108\ttotal: 8.48s\tremaining: 808ms\n",
            "913:\tlearn: 0.0095059\ttotal: 8.48s\tremaining: 798ms\n",
            "914:\tlearn: 0.0094903\ttotal: 8.5s\tremaining: 790ms\n",
            "915:\tlearn: 0.0094763\ttotal: 8.52s\tremaining: 781ms\n",
            "916:\tlearn: 0.0094523\ttotal: 8.53s\tremaining: 772ms\n",
            "917:\tlearn: 0.0094482\ttotal: 8.54s\tremaining: 763ms\n",
            "918:\tlearn: 0.0094390\ttotal: 8.54s\tremaining: 753ms\n",
            "919:\tlearn: 0.0094248\ttotal: 8.55s\tremaining: 744ms\n",
            "920:\tlearn: 0.0094062\ttotal: 8.56s\tremaining: 734ms\n",
            "921:\tlearn: 0.0093910\ttotal: 8.57s\tremaining: 725ms\n",
            "922:\tlearn: 0.0093694\ttotal: 8.58s\tremaining: 716ms\n",
            "923:\tlearn: 0.0093471\ttotal: 8.59s\tremaining: 706ms\n",
            "924:\tlearn: 0.0093320\ttotal: 8.59s\tremaining: 697ms\n",
            "925:\tlearn: 0.0093317\ttotal: 8.6s\tremaining: 687ms\n",
            "926:\tlearn: 0.0093124\ttotal: 8.61s\tremaining: 678ms\n",
            "927:\tlearn: 0.0092943\ttotal: 8.62s\tremaining: 668ms\n",
            "928:\tlearn: 0.0092907\ttotal: 8.62s\tremaining: 659ms\n",
            "929:\tlearn: 0.0092894\ttotal: 8.63s\tremaining: 650ms\n",
            "930:\tlearn: 0.0092711\ttotal: 8.64s\tremaining: 640ms\n",
            "931:\tlearn: 0.0092612\ttotal: 8.64s\tremaining: 631ms\n",
            "932:\tlearn: 0.0092348\ttotal: 8.65s\tremaining: 621ms\n",
            "933:\tlearn: 0.0092236\ttotal: 8.66s\tremaining: 612ms\n",
            "934:\tlearn: 0.0092059\ttotal: 8.67s\tremaining: 603ms\n",
            "935:\tlearn: 0.0091964\ttotal: 8.67s\tremaining: 593ms\n",
            "936:\tlearn: 0.0091767\ttotal: 8.68s\tremaining: 584ms\n",
            "937:\tlearn: 0.0091618\ttotal: 8.69s\tremaining: 574ms\n",
            "938:\tlearn: 0.0091452\ttotal: 8.7s\tremaining: 565ms\n",
            "939:\tlearn: 0.0091192\ttotal: 8.7s\tremaining: 556ms\n",
            "940:\tlearn: 0.0090984\ttotal: 8.71s\tremaining: 546ms\n",
            "941:\tlearn: 0.0090959\ttotal: 8.72s\tremaining: 537ms\n",
            "942:\tlearn: 0.0090827\ttotal: 8.73s\tremaining: 528ms\n",
            "943:\tlearn: 0.0090813\ttotal: 8.74s\tremaining: 518ms\n",
            "944:\tlearn: 0.0090782\ttotal: 8.75s\tremaining: 509ms\n",
            "945:\tlearn: 0.0090762\ttotal: 8.75s\tremaining: 500ms\n",
            "946:\tlearn: 0.0090613\ttotal: 8.76s\tremaining: 490ms\n",
            "947:\tlearn: 0.0090457\ttotal: 8.77s\tremaining: 481ms\n",
            "948:\tlearn: 0.0090431\ttotal: 8.78s\tremaining: 472ms\n",
            "949:\tlearn: 0.0090413\ttotal: 8.79s\tremaining: 462ms\n",
            "950:\tlearn: 0.0090191\ttotal: 8.79s\tremaining: 453ms\n",
            "951:\tlearn: 0.0090087\ttotal: 8.8s\tremaining: 444ms\n",
            "952:\tlearn: 0.0090062\ttotal: 8.81s\tremaining: 434ms\n",
            "953:\tlearn: 0.0089914\ttotal: 8.81s\tremaining: 425ms\n",
            "954:\tlearn: 0.0089888\ttotal: 8.82s\tremaining: 416ms\n",
            "955:\tlearn: 0.0089741\ttotal: 8.83s\tremaining: 406ms\n",
            "956:\tlearn: 0.0089568\ttotal: 8.84s\tremaining: 397ms\n",
            "957:\tlearn: 0.0089494\ttotal: 8.84s\tremaining: 388ms\n",
            "958:\tlearn: 0.0089366\ttotal: 8.85s\tremaining: 378ms\n",
            "959:\tlearn: 0.0089318\ttotal: 8.86s\tremaining: 369ms\n",
            "960:\tlearn: 0.0089269\ttotal: 8.87s\tremaining: 360ms\n",
            "961:\tlearn: 0.0089132\ttotal: 8.87s\tremaining: 351ms\n",
            "962:\tlearn: 0.0089072\ttotal: 8.88s\tremaining: 341ms\n",
            "963:\tlearn: 0.0088860\ttotal: 8.89s\tremaining: 332ms\n",
            "964:\tlearn: 0.0088691\ttotal: 8.89s\tremaining: 323ms\n",
            "965:\tlearn: 0.0088591\ttotal: 8.9s\tremaining: 313ms\n",
            "966:\tlearn: 0.0088522\ttotal: 8.91s\tremaining: 304ms\n",
            "967:\tlearn: 0.0088494\ttotal: 8.92s\tremaining: 295ms\n",
            "968:\tlearn: 0.0088329\ttotal: 8.92s\tremaining: 286ms\n",
            "969:\tlearn: 0.0088162\ttotal: 8.93s\tremaining: 276ms\n",
            "970:\tlearn: 0.0088122\ttotal: 8.94s\tremaining: 267ms\n",
            "971:\tlearn: 0.0088093\ttotal: 8.95s\tremaining: 258ms\n",
            "972:\tlearn: 0.0087965\ttotal: 8.95s\tremaining: 248ms\n",
            "973:\tlearn: 0.0087753\ttotal: 8.96s\tremaining: 239ms\n",
            "974:\tlearn: 0.0087739\ttotal: 8.97s\tremaining: 230ms\n",
            "975:\tlearn: 0.0087722\ttotal: 8.98s\tremaining: 221ms\n",
            "976:\tlearn: 0.0087593\ttotal: 8.99s\tremaining: 212ms\n",
            "977:\tlearn: 0.0087416\ttotal: 8.99s\tremaining: 202ms\n",
            "978:\tlearn: 0.0087401\ttotal: 9s\tremaining: 193ms\n",
            "979:\tlearn: 0.0087202\ttotal: 9.01s\tremaining: 184ms\n",
            "980:\tlearn: 0.0087188\ttotal: 9.02s\tremaining: 175ms\n",
            "981:\tlearn: 0.0086970\ttotal: 9.02s\tremaining: 165ms\n",
            "982:\tlearn: 0.0086813\ttotal: 9.03s\tremaining: 156ms\n",
            "983:\tlearn: 0.0086734\ttotal: 9.04s\tremaining: 147ms\n",
            "984:\tlearn: 0.0086533\ttotal: 9.04s\tremaining: 138ms\n",
            "985:\tlearn: 0.0086318\ttotal: 9.05s\tremaining: 129ms\n",
            "986:\tlearn: 0.0086172\ttotal: 9.06s\tremaining: 119ms\n",
            "987:\tlearn: 0.0086133\ttotal: 9.07s\tremaining: 110ms\n",
            "988:\tlearn: 0.0086119\ttotal: 9.07s\tremaining: 101ms\n",
            "989:\tlearn: 0.0086109\ttotal: 9.08s\tremaining: 91.7ms\n",
            "990:\tlearn: 0.0085946\ttotal: 9.09s\tremaining: 82.6ms\n",
            "991:\tlearn: 0.0085759\ttotal: 9.1s\tremaining: 73.4ms\n",
            "992:\tlearn: 0.0085579\ttotal: 9.1s\tremaining: 64.2ms\n",
            "993:\tlearn: 0.0085551\ttotal: 9.11s\tremaining: 55ms\n",
            "994:\tlearn: 0.0085517\ttotal: 9.12s\tremaining: 45.8ms\n",
            "995:\tlearn: 0.0085454\ttotal: 9.13s\tremaining: 36.7ms\n",
            "996:\tlearn: 0.0085373\ttotal: 9.13s\tremaining: 27.5ms\n",
            "997:\tlearn: 0.0085203\ttotal: 9.14s\tremaining: 18.3ms\n",
            "998:\tlearn: 0.0085171\ttotal: 9.15s\tremaining: 9.16ms\n",
            "999:\tlearn: 0.0085155\ttotal: 9.15s\tremaining: 0us\n",
            "The accuracy score is: 0.9532163742690059\n",
            "The confusion matrix is : \n",
            " [[ 58   5]\n",
            " [  3 105]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Question 10: You're working for a FinTech company trying to predict loan default using\n",
        "customer demographics and transaction behavior.\n",
        "The dataset is imbalanced, contains missing values, and has both numeric and\n",
        "categorical features.\n",
        "Describe your step-by-step data science pipeline using boosting techniques:\n",
        "● Data preprocessing & handling missing/categorical values\n",
        "● Choice between AdaBoost, XGBoost, or CatBoost\n",
        "● Hyperparameter tuning strategy\n",
        "● Evaluation metrics you'd choose and why\n",
        "● How the business would benefit from your model\n",
        "Answer: -> Data Preprocessing & Handling Missing/Categorical Values:\n",
        "1. Handling Missing Values:\n",
        "- For numerical features, impute missing values using median/mean or advanced methods (KNN imputation).\n",
        "- For categorical features, impute with mode or use a separate “missing” category.\n",
        "\n",
        "2. Feature Encoding:\n",
        "- If using XGBoost/AdaBoost → Apply One-Hot Encoding (OHE) or Target Encoding for categorical variables.\n",
        "- If using CatBoost → Directly pass categorical feature indices, since CatBoost handles categorical variables natively without heavy preprocessing.\n",
        "\n",
        "3. Feature Scaling\n",
        "- Not strictly required for tree-based boosting models.\n",
        "- Can apply normalization if using models like Logistic Regression for baseline comparison.\n",
        "\n",
        "-> Choose a Boosting Algorithm:\n",
        "CatBoost will be preferred because it can automate the encoding of categorical features without extensive preprocessing and hadles it  natively.\n",
        "It also works well on imbalanced data with built in class weights.\n",
        "Efficient and robust to overfitting as compares to AdaBoost and XGBoost.\n",
        "\n",
        "-> Hyperparameter Tuning Strategy:\n",
        "Use GridSearchCV or RandomizedSearchCV with stratified folds to tune:\n",
        "- learning_rate → Controls step size of updates (e.g., 0.01, 0.05, 0.1).\n",
        "- n_estimators → Number of trees (e.g., 100, 500, 1000).\n",
        "- max_depth → Controls complexity of trees (e.g., 3–10).\n",
        "- class_weights → To handle imbalance.\n",
        "- subsample & colsample_bylevel → For regularization to prevent overfitting.\n",
        "\n",
        "-> Evaluation metrics:\n",
        "SInce it is a imbalanced classification datasets, accuracy can be misleading.\n",
        "We would prefer ROC-AUC curve, precision, recall, F1-score, Confusion Matrix.\n",
        "\n",
        "-> Business Impact\n",
        "- Reduce Financial Risk: Early identification of potential defaulters → reduces loan loss.\n",
        "- Improve Credit Policies: Helps refine risk-based pricing of loans.\n",
        "- Operational Efficiency: Automates decision-making, reducing reliance on manual underwriting.\n",
        "- Customer Retention: Helps offer flexible repayment plans to at-risk customers, improving trust.\n",
        "'''"
      ],
      "metadata": {
        "id": "2_22W8dRleR2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}